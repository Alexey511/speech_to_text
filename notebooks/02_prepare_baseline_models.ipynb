{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подготовка Baseline Моделей\n",
    "\n",
    "Этот ноутбук загружает предобученные модели из HuggingFace и сохраняет их локально для baseline оценки.\n",
    "\n",
    "**Модели:**\n",
    "- Whisper Small (без дообучения)\n",
    "- Whisper Base (без дообучения)\n",
    "- Speech2Text Cross-Lingual (английская модель + multilingual tokenizer, без обучения)\n",
    "\n",
    "**Сохранение:**\n",
    "Все модели сохраняются в `experiments/baselines/` в нашем custom checkpoint формате:\n",
    "- `model_weights.pt` - веса модели\n",
    "- `model_metadata.json` - метаданные (model_type, model_name, tokenizer_name_or_path, target_language, epoch)\n",
    "- `config.yaml` - полный конфиг проекта для evaluation.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: c:\\Users\\User\\Documents\\Progs\\Projects\\seepch_to_text\n",
      "PyTorch version: 2.5.1\n",
      "CUDA available: True\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import shutil\n",
    "\n",
    "# Add src to path\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "# Import our modules\n",
    "from src.config import ProjectConfig, ModelConfig, load_config\n",
    "from src.models import ModelManager\n",
    "from src.data import DataManager\n",
    "\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Whisper Small (Baseline)\n",
    "\n",
    "Загрузка `openai/whisper-small` без дообучения.\n",
    "\n",
    "Модель будет сохранена в:\n",
    "- `experiments/baselines/whisper-small/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Loading Whisper Small...\n",
      "============================================================\n",
      "Config loaded: openai/whisper-small\n",
      "✓ Processor created: WhisperProcessor\n",
      "✓ Model created: WhisperSTT\n",
      "\n",
      "⚠️  Принудительная заморозка всех параметров для baseline модели...\n",
      "\n",
      "Model parameters:\n",
      "  Total: 241,734,912\n",
      "  Trainable: 0\n",
      "  Frozen: True\n",
      "\n",
      "Saving to: c:\\Users\\User\\Documents\\Progs\\Projects\\seepch_to_text\\experiments\\baselines\\whisper-small\n",
      "✓ Config copied to: c:\\Users\\User\\Documents\\Progs\\Projects\\seepch_to_text\\experiments\\baselines\\whisper-small\\config.yaml\n",
      "\n",
      "✅ Whisper Small baseline готов!\n",
      "   Checkpoint structure:\n",
      "     - c:\\Users\\User\\Documents\\Progs\\Projects\\seepch_to_text\\experiments\\baselines\\whisper-small\\model_weights.pt (fully frozen)\n",
      "     - c:\\Users\\User\\Documents\\Progs\\Projects\\seepch_to_text\\experiments\\baselines\\whisper-small\\model_metadata.json\n",
      "     - c:\\Users\\User\\Documents\\Progs\\Projects\\seepch_to_text\\experiments\\baselines\\whisper-small\\config.yaml (freeze settings для train.py)\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"Loading Whisper Small...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Load config\n",
    "config_path = project_root / \"configs\" / \"whisper_small.yaml\"\n",
    "config = load_config(config_path)\n",
    "\n",
    "print(f\"Config loaded: {config.model.model_name}\")\n",
    "\n",
    "# Create DataManager to setup processor (pass full ProjectConfig)\n",
    "data_manager = DataManager(config)\n",
    "processor = data_manager.setup_processor(\n",
    "    model_name=config.model.model_name,\n",
    "    model_type=config.model.model_type,\n",
    "    language=config.data.language,\n",
    "    task=config.data.task\n",
    ")\n",
    "print(f\"✓ Processor created: {type(processor).__name__}\")\n",
    "\n",
    "# Create ModelManager and model\n",
    "model_manager = ModelManager()\n",
    "model = model_manager.create_model(config.model, processor)\n",
    "print(f\"✓ Model created: {type(model).__name__}\")\n",
    "\n",
    "# ВАЖНО: Baseline модели ВСЕГДА полностью замораживаются (независимо от конфига)\n",
    "print(\"\\n⚠️  Принудительная заморозка всех параметров для baseline модели...\")\n",
    "model.freeze_feature_encoder()\n",
    "model.freeze_encoder()\n",
    "model.freeze_decoder()\n",
    "\n",
    "# Verify freezing\n",
    "trainable = model.get_trainable_parameters()\n",
    "total = model.get_num_parameters()\n",
    "print(f\"\\nModel parameters:\")\n",
    "print(f\"  Total: {total:,}\")\n",
    "print(f\"  Trainable: {trainable:,}\")\n",
    "print(f\"  Frozen: {trainable == 0}\")\n",
    "\n",
    "# Save in our custom checkpoint format (epoch=None for baseline)\n",
    "if trainable == 0:\n",
    "    save_dir = project_root / \"experiments\" / \"baselines\" / \"whisper-small\"\n",
    "    print(f\"\\nSaving to: {save_dir}\")\n",
    "    \n",
    "    # Save checkpoint (model_weights.pt + model_metadata.json)\n",
    "    model_manager.save_checkpoint(model, config.model, str(save_dir))\n",
    "    \n",
    "    # Copy config.yaml to checkpoint directory for evaluation.py\n",
    "    # Конфиг сохраняется как есть - train.py применит freeze/unfreeze из конфига при загрузке\n",
    "    config_dest = save_dir / \"config.yaml\"\n",
    "    shutil.copy(config_path, config_dest)\n",
    "    print(f\"✓ Config copied to: {config_dest}\")\n",
    "    \n",
    "    print(\"\\n✅ Whisper Small baseline готов!\")\n",
    "    print(f\"   Checkpoint structure:\")\n",
    "    print(f\"     - {save_dir / 'model_weights.pt'} (fully frozen)\")\n",
    "    print(f\"     - {save_dir / 'model_metadata.json'}\")\n",
    "    print(f\"     - {save_dir / 'config.yaml'} (freeze settings для train.py)\")\n",
    "else:\n",
    "    print(f\"\\n❌ Ошибка: Не все параметры заморожены! (trainable={trainable:,})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Whisper Base (Baseline)\n",
    "\n",
    "Загрузка `openai/whisper-base` без дообучения.\n",
    "\n",
    "Модель будет сохранена в:\n",
    "- `experiments/baselines/whisper-base/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Loading Whisper Base...\n",
      "============================================================\n",
      "Config loaded: openai/whisper-base\n",
      "✓ Processor created: WhisperProcessor\n",
      "✓ Model created: WhisperSTT\n",
      "\n",
      "⚠️  Принудительная заморозка всех параметров для baseline модели...\n",
      "\n",
      "Model parameters:\n",
      "  Total: 72,593,920\n",
      "  Trainable: 0\n",
      "  Frozen: True\n",
      "\n",
      "Saving to: c:\\Users\\User\\Documents\\Progs\\Projects\\seepch_to_text\\experiments\\baselines\\whisper-base\n",
      "✓ Config copied to: c:\\Users\\User\\Documents\\Progs\\Projects\\seepch_to_text\\experiments\\baselines\\whisper-base\\config.yaml\n",
      "\n",
      "✅ Whisper Base baseline готов!\n",
      "   Checkpoint structure:\n",
      "     - c:\\Users\\User\\Documents\\Progs\\Projects\\seepch_to_text\\experiments\\baselines\\whisper-base\\model_weights.pt (fully frozen)\n",
      "     - c:\\Users\\User\\Documents\\Progs\\Projects\\seepch_to_text\\experiments\\baselines\\whisper-base\\model_metadata.json\n",
      "     - c:\\Users\\User\\Documents\\Progs\\Projects\\seepch_to_text\\experiments\\baselines\\whisper-base\\config.yaml (freeze settings для train.py)\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"Loading Whisper Base...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Load config\n",
    "config_path = project_root / \"configs\" / \"whisper_base.yaml\"\n",
    "config = load_config(config_path)\n",
    "\n",
    "print(f\"Config loaded: {config.model.model_name}\")\n",
    "\n",
    "# Create DataManager to setup processor (pass full ProjectConfig)\n",
    "data_manager = DataManager(config)\n",
    "processor = data_manager.setup_processor(\n",
    "    model_name=config.model.model_name,\n",
    "    model_type=config.model.model_type,\n",
    "    language=config.data.language,\n",
    "    task=config.data.task\n",
    ")\n",
    "print(f\"✓ Processor created: {type(processor).__name__}\")\n",
    "\n",
    "# Create model (reuse existing ModelManager)\n",
    "model = model_manager.create_model(config.model, processor)\n",
    "print(f\"✓ Model created: {type(model).__name__}\")\n",
    "\n",
    "# ВАЖНО: Baseline модели ВСЕГДА полностью замораживаются (независимо от конфига)\n",
    "print(\"\\n⚠️  Принудительная заморозка всех параметров для baseline модели...\")\n",
    "model.freeze_feature_encoder()\n",
    "model.freeze_encoder()\n",
    "model.freeze_decoder()\n",
    "\n",
    "# Verify freezing\n",
    "trainable = model.get_trainable_parameters()\n",
    "total = model.get_num_parameters()\n",
    "print(f\"\\nModel parameters:\")\n",
    "print(f\"  Total: {total:,}\")\n",
    "print(f\"  Trainable: {trainable:,}\")\n",
    "print(f\"  Frozen: {trainable == 0}\")\n",
    "\n",
    "# Save in our custom checkpoint format\n",
    "if trainable == 0:\n",
    "    save_dir = project_root / \"experiments\" / \"baselines\" / \"whisper-base\"\n",
    "    print(f\"\\nSaving to: {save_dir}\")\n",
    "    \n",
    "    # Save checkpoint (model_weights.pt + model_metadata.json)\n",
    "    model_manager.save_checkpoint(model, config.model, str(save_dir))\n",
    "    \n",
    "    # Copy config.yaml to checkpoint directory for evaluation.py\n",
    "    config_dest = save_dir / \"config.yaml\"\n",
    "    shutil.copy(config_path, config_dest)\n",
    "    print(f\"✓ Config copied to: {config_dest}\")\n",
    "    \n",
    "    print(\"\\n✅ Whisper Base baseline готов!\")\n",
    "    print(f\"   Checkpoint structure:\")\n",
    "    print(f\"     - {save_dir / 'model_weights.pt'} (fully frozen)\")\n",
    "    print(f\"     - {save_dir / 'model_metadata.json'}\")\n",
    "    print(f\"     - {save_dir / 'config.yaml'} (freeze settings для train.py)\")\n",
    "else:\n",
    "    print(f\"\\n❌ Ошибка: Не все параметры заморожены! (trainable={trainable:,})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Speech2Text Cross-Lingual (Baseline - No Training)\n",
    "\n",
    "Загрузка английской модели `facebook/s2t-small-librispeech-asr` с multilingual tokenizer `facebook/s2t-medium-mustc-multilingual-st` для русского языка.\n",
    "\n",
    "**Cross-Lingual Transfer Setup:**\n",
    "- Encoder: Pretrained на английской речи (LibriSpeech)\n",
    "- Decoder: Embeddings resized для multilingual tokenizer (10000 tokens)\n",
    "- Target language: Russian (ru)\n",
    "- Fully frozen (без обучения)\n",
    "\n",
    "**Цель:** Оценить начальную точность модели ДО обучения (ожидаем низкую точность, т.к. decoder не обучен на русском).\n",
    "\n",
    "Модель будет сохранена в:\n",
    "- `experiments/baselines/s2t-cross-lingual/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Loading Speech2Text Cross-Lingual (English model + Multilingual tokenizer)...\n",
      "============================================================\n",
      "Config loaded: facebook/s2t-small-librispeech-asr\n",
      "Tokenizer: facebook/s2t-medium-mustc-multilingual-st\n",
      "Target language: ru\n",
      "✓ Processor created: Speech2TextProcessor\n",
      "✓ Multilingual tokenizer with 8 languages: ['pt', 'fr', 'ru', 'nl', 'ro', 'it', 'es', 'de']\n",
      "✓ Target language 'ru' supported: True\n",
      "✓ Model created: Speech2TextSTT\n",
      "\n",
      "⚠️  Принудительная заморозка всех параметров для baseline модели...\n",
      "\n",
      "Model parameters:\n",
      "  Total: 29,536,256\n",
      "  Trainable: 0\n",
      "  Frozen: True\n",
      "\n",
      "Saving to: c:\\Users\\User\\Documents\\Progs\\Projects\\seepch_to_text\\experiments\\baselines\\s2t-cross-lingual\n",
      "✓ Config copied to: c:\\Users\\User\\Documents\\Progs\\Projects\\seepch_to_text\\experiments\\baselines\\s2t-cross-lingual\\config.yaml\n",
      "\n",
      "✅ Speech2Text Cross-Lingual baseline готов!\n",
      "   Checkpoint structure:\n",
      "     - c:\\Users\\User\\Documents\\Progs\\Projects\\seepch_to_text\\experiments\\baselines\\s2t-cross-lingual\\model_weights.pt (fully frozen)\n",
      "     - c:\\Users\\User\\Documents\\Progs\\Projects\\seepch_to_text\\experiments\\baselines\\s2t-cross-lingual\\model_metadata.json\n",
      "     - c:\\Users\\User\\Documents\\Progs\\Projects\\seepch_to_text\\experiments\\baselines\\s2t-cross-lingual\\config.yaml (freeze settings для train.py)\n",
      "\n",
      "⚠️  ВАЖНО: Эта модель НЕ ОБУЧЕНА на русском!\n",
      "   Ожидаемые результаты evaluation: очень низкая точность (WER ~100%)\n",
      "   Decoder был resized под русский токенизатор, но weights случайные.\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"Loading Speech2Text Cross-Lingual (English model + Multilingual tokenizer)...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Load config\n",
    "config_path = project_root / \"configs\" / \"s2t_cross_lingual.yaml\"\n",
    "config = load_config(config_path)\n",
    "\n",
    "print(f\"Config loaded: {config.model.model_name}\")\n",
    "print(f\"Tokenizer: {config.model.tokenizer_name_or_path}\")\n",
    "print(f\"Target language: {config.data.language}\")\n",
    "\n",
    "# Create DataManager to setup processor with alternative tokenizer\n",
    "data_manager = DataManager(config)\n",
    "processor = data_manager.setup_processor(\n",
    "    model_name=config.model.model_name,\n",
    "    model_type=config.model.model_type,\n",
    "    language=config.data.language,\n",
    "    task=config.data.task,\n",
    "    tokenizer_name_or_path=config.model.tokenizer_name_or_path\n",
    ")\n",
    "print(f\"✓ Processor created: {type(processor).__name__}\")\n",
    "\n",
    "# Verify tokenizer language support\n",
    "tokenizer = getattr(processor, 'tokenizer', None)\n",
    "if tokenizer and hasattr(tokenizer, 'lang_code_to_id'):\n",
    "    print(f\"✓ Multilingual tokenizer with {len(tokenizer.lang_code_to_id)} languages: {list(tokenizer.lang_code_to_id.keys())}\")\n",
    "    print(f\"✓ Target language 'ru' supported: {'ru' in tokenizer.lang_code_to_id}\")\n",
    "\n",
    "# Create model (will automatically resize embeddings for multilingual tokenizer)\n",
    "model = model_manager.create_model(config.model, processor)\n",
    "print(f\"✓ Model created: {type(model).__name__}\")\n",
    "\n",
    "# ВАЖНО: Baseline модели ВСЕГДА полностью замораживаются (независимо от конфига)\n",
    "print(\"\\n⚠️  Принудительная заморозка всех параметров для baseline модели...\")\n",
    "model.freeze_feature_encoder()\n",
    "model.freeze_encoder()\n",
    "model.freeze_decoder()\n",
    "\n",
    "# Verify freezing\n",
    "trainable = model.get_trainable_parameters()\n",
    "total = model.get_num_parameters()\n",
    "print(f\"\\nModel parameters:\")\n",
    "print(f\"  Total: {total:,}\")\n",
    "print(f\"  Trainable: {trainable:,}\")\n",
    "print(f\"  Frozen: {trainable == 0}\")\n",
    "\n",
    "# Save in our custom checkpoint format\n",
    "if trainable == 0:\n",
    "    save_dir = project_root / \"experiments\" / \"baselines\" / \"s2t-cross-lingual\"\n",
    "    print(f\"\\nSaving to: {save_dir}\")\n",
    "    \n",
    "    # Save checkpoint (model_weights.pt + model_metadata.json with tokenizer info)\n",
    "    model_manager.save_checkpoint(model, config.model, str(save_dir))\n",
    "    \n",
    "    # Copy config.yaml to checkpoint directory for evaluation.py\n",
    "    config_dest = save_dir / \"config.yaml\"\n",
    "    shutil.copy(config_path, config_dest)\n",
    "    print(f\"✓ Config copied to: {config_dest}\")\n",
    "    \n",
    "    print(\"\\n✅ Speech2Text Cross-Lingual baseline готов!\")\n",
    "    print(f\"   Checkpoint structure:\")\n",
    "    print(f\"     - {save_dir / 'model_weights.pt'} (fully frozen)\")\n",
    "    print(f\"     - {save_dir / 'model_metadata.json'}\")\n",
    "    print(f\"     - {save_dir / 'config.yaml'} (freeze settings для train.py)\")\n",
    "    print(\"\\n⚠️  ВАЖНО: Эта модель НЕ ОБУЧЕНА на русском!\")\n",
    "    print(\"   Ожидаемые результаты evaluation: очень низкая точность (WER ~100%)\")\n",
    "    print(\"   Decoder был resized под русский токенизатор, но weights случайные.\")\n",
    "else:\n",
    "    print(f\"\\n❌ Ошибка: Не все параметры заморожены! (trainable={trainable:,})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сводка\n",
    "\n",
    "Проверка всех сохраненных baseline моделей.\n",
    "\n",
    "Каждая модель должна содержать:\n",
    "- `model_weights.pt` - веса модели\n",
    "- `model_metadata.json` - метаданные чекпоинта\n",
    "- `config.yaml` - конфигурация для evaluation.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Сохраненные Baseline Модели\n",
      "============================================================\n",
      "✅ s2t-cross-lingual\n",
      "   Path: c:\\Users\\User\\Documents\\Progs\\Projects\\seepch_to_text\\experiments\\baselines\\s2t-cross-lingual\n",
      "   Size: 112.8 MB\n",
      "   Files: Weights=True, Metadata=True, Config=True\n",
      "\n",
      "✅ whisper-base\n",
      "   Path: c:\\Users\\User\\Documents\\Progs\\Projects\\seepch_to_text\\experiments\\baselines\\whisper-base\n",
      "   Size: 277.0 MB\n",
      "   Files: Weights=True, Metadata=True, Config=True\n",
      "\n",
      "✅ whisper-small\n",
      "   Path: c:\\Users\\User\\Documents\\Progs\\Projects\\seepch_to_text\\experiments\\baselines\\whisper-small\n",
      "   Size: 922.3 MB\n",
      "   Files: Weights=True, Metadata=True, Config=True\n",
      "\n",
      "============================================================\n",
      "\n",
      "Теперь можно запустить evaluation.py через VSCode 'Run' кнопку!\n",
      "\n",
      "ИЛИ через командную строку:\n",
      "\n",
      "# Whisper Small baseline\n",
      "python evaluation.py --model-path experiments/baselines/whisper-small\n",
      "\n",
      "# Whisper Base baseline\n",
      "python evaluation.py --model-path experiments/baselines/whisper-base\n",
      "\n",
      "# Speech2Text Cross-Lingual baseline\n",
      "python evaluation.py --model-path experiments/baselines/s2t-cross-lingual\n",
      "\n",
      "Конфиг будет автоматически найден в директории модели!\n"
     ]
    }
   ],
   "source": [
    "baselines_dir = project_root / \"experiments\" / \"baselines\"\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"Сохраненные Baseline Модели\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if baselines_dir.exists():\n",
    "    for model_dir in sorted(baselines_dir.iterdir()):\n",
    "        if model_dir.is_dir():\n",
    "            # Check for required checkpoint files (our custom format)\n",
    "            has_weights = (model_dir / \"model_weights.pt\").exists()\n",
    "            has_metadata = (model_dir / \"model_metadata.json\").exists()\n",
    "            has_config = (model_dir / \"config.yaml\").exists()\n",
    "            \n",
    "            status = \"✅\" if (has_weights and has_metadata and has_config) else \"❌\"\n",
    "            \n",
    "            # Calculate total size\n",
    "            total_size = sum(f.stat().st_size for f in model_dir.rglob('*') if f.is_file())\n",
    "            size_mb = total_size / (1024 * 1024)\n",
    "            \n",
    "            print(f\"{status} {model_dir.name}\")\n",
    "            print(f\"   Path: {model_dir}\")\n",
    "            print(f\"   Size: {size_mb:.1f} MB\")\n",
    "            print(f\"   Files: Weights={has_weights}, Metadata={has_metadata}, Config={has_config}\")\n",
    "            print()\n",
    "else:\n",
    "    print(\"❌ Директория baselines не найдена\")\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"\\nТеперь можно запустить evaluation.py через VSCode 'Run' кнопку!\")\n",
    "print(\"\\nИЛИ через командную строку:\")\n",
    "print(\"\\n# Whisper Small baseline\")\n",
    "print(\"python evaluation.py --model-path experiments/baselines/whisper-small\")\n",
    "print(\"\\n# Whisper Base baseline\")\n",
    "print(\"python evaluation.py --model-path experiments/baselines/whisper-base\")\n",
    "print(\"\\n# Speech2Text Cross-Lingual baseline\")\n",
    "print(\"python evaluation.py --model-path experiments/baselines/s2t-cross-lingual\")\n",
    "print(\"\\nКонфиг будет автоматически найден в директории модели!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Поддерживается 8 языков:\n",
      "\n",
      "pt\n",
      "fr\n",
      "ru\n",
      "nl\n",
      "ro\n",
      "it\n",
      "es\n",
      "de\n"
     ]
    }
   ],
   "source": [
    "from transformers import Speech2TextTokenizer\n",
    "\n",
    "# Загружаем токенизатор\n",
    "tokenizer = Speech2TextTokenizer.from_pretrained(\"facebook/s2t-medium-mustc-multilingual-st\")\n",
    "\n",
    "# Проверяем список поддерживаемых языков\n",
    "if hasattr(tokenizer, \"langs\") and tokenizer.langs is not None:\n",
    "    print(f\"Поддерживается {len(tokenizer.langs)} языков:\\n\")\n",
    "    for lang in tokenizer.langs:\n",
    "        print(lang)\n",
    "else:\n",
    "    print(\"Этот токенизатор не содержит списка поддерживаемых языков.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basenn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
