"""
–ê–Ω–∞–ª–∏–∑ –∫–æ–¥–∞ –∑–∞–º–æ—Ä–æ–∑–∫–∏ - —á—Ç–æ –∏–º–µ–Ω–Ω–æ –∑–∞–º–æ—Ä–∞–∂–∏–≤–∞–µ—Ç—Å—è
"""
print("="*80)
print("–ê–ù–ê–õ–ò–ó –ö–û–î–ê –ó–ê–ú–û–†–û–ó–ö–ò –ò–ó src/models.py")
print("="*80)

print("\n1Ô∏è‚É£ WHISPER - –º–µ—Ç–æ–¥ freeze_encoder() (—Å—Ç—Ä–æ–∫–∏ 293-296):")
print("-"*80)
print("""
def freeze_encoder(self):
    for param in self.model.model.encoder.parameters():
        param.requires_grad = False
    logger.info("Encoder frozen")
""")
print("\nüìå –ó–∞–º–æ—Ä–∞–∂–∏–≤–∞–µ—Ç: self.model.model.encoder")
print("   –í–∫–ª—é—á–∞–µ—Ç:")
print("   - conv1, conv2 (feature extraction)")
print("   - embed_positions (positional encoding)")
print("   - layers[0..N] (–≤—Å–µ transformer layers)")
print("\nüìå –ù–ï –∑–∞—Ç—Ä–∞–≥–∏–≤–∞–µ—Ç:")
print("   ‚úÖ self.model.model.decoder.embed_tokens (input embeddings)")
print("   ‚úÖ self.model.proj_out (output projection)")

print("\n" + "-"*80)
print("2Ô∏è‚É£ WHISPER - –º–µ—Ç–æ–¥ freeze_decoder() (—Å—Ç—Ä–æ–∫–∏ 298-301):")
print("-"*80)
print("""
def freeze_decoder(self):
    for param in self.model.model.decoder.parameters():
        param.requires_grad = False
    logger.info("Decoder frozen")
""")
print("\nüìå –ó–∞–º–æ—Ä–∞–∂–∏–≤–∞–µ—Ç: self.model.model.decoder")
print("   –í–∫–ª—é—á–∞–µ—Ç:")
print("   - embed_tokens (token embeddings) ‚ùå –ó–ê–ú–ï–†–ó!")
print("   - embed_positions (positional encoding)")
print("   - layers[0..N] (–≤—Å–µ transformer layers)")
print("\nüìå –ù–ï –∑–∞—Ç—Ä–∞–≥–∏–≤–∞–µ—Ç:")
print("   ‚úÖ self.model.proj_out (output projection, –Ω–µ —á–∞—Å—Ç—å decoder)")

print("\n" + "="*80)
print("\n3Ô∏è‚É£ SPEECH2TEXT - –º–µ—Ç–æ–¥ freeze_encoder() (—Å—Ç—Ä–æ–∫–∏ 499-502):")
print("-"*80)
print("""
def freeze_encoder(self):
    for param in self.model.model.encoder.parameters():
        param.requires_grad = False
    logger.info("Encoder frozen")
""")
print("\nüìå –ó–∞–º–æ—Ä–∞–∂–∏–≤–∞–µ—Ç: self.model.model.encoder")
print("   –í–∫–ª—é—á–∞–µ—Ç:")
print("   - conv layers (feature extraction)")
print("   - embed_positions (positional encoding)")
print("   - layers[0..N] (–≤—Å–µ transformer layers)")
print("\nüìå –ù–ï –∑–∞—Ç—Ä–∞–≥–∏–≤–∞–µ—Ç:")
print("   ‚úÖ self.model.model.decoder.embed_tokens (input embeddings)")
print("   ‚úÖ self.model.lm_head (output projection)")

print("\n" + "-"*80)
print("4Ô∏è‚É£ SPEECH2TEXT - –º–µ—Ç–æ–¥ freeze_decoder() (—Å—Ç—Ä–æ–∫–∏ 504-507):")
print("-"*80)
print("""
def freeze_decoder(self):
    for param in self.model.model.decoder.parameters():
        param.requires_grad = False
    logger.info("Decoder frozen")
""")
print("\nüìå –ó–∞–º–æ—Ä–∞–∂–∏–≤–∞–µ—Ç: self.model.model.decoder")
print("   –í–∫–ª—é—á–∞–µ—Ç:")
print("   - embed_tokens (token embeddings) ‚ùå –ó–ê–ú–ï–†–ó!")
print("   - embed_positions (positional encoding)")
print("   - layers[0..N] (–≤—Å–µ transformer layers)")
print("\nüìå –ù–ï –∑–∞—Ç—Ä–∞–≥–∏–≤–∞–µ—Ç:")
print("   ‚úÖ self.model.lm_head (output projection, –Ω–µ —á–∞—Å—Ç—å decoder)")

print("\n" + "="*80)
print("–û–¢–í–ï–¢ –ù–ê –í–û–ü–†–û–°")
print("="*80)
print("""
‚ùì –í–æ–ø—Ä–æ—Å: "–ö–æ–≥–¥–∞ –º—ã —Ä–∞–∑–º–æ—Ä–∞–∂–∏–≤–∞–µ–º/–∑–∞–º–æ—Ä–∞–∂–∏–≤–∞–µ–º –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ —Å–ª–æ–∏ -
           —ç–º–±–µ–¥–∏–Ω–≥–∏ –≤—Å–µ–≥–¥–∞ –æ—Å—Ç–∞—é—Ç—Å—è —Ä–∞–∑–º–æ—Ä–æ–∂–µ–Ω–Ω—ã–º–∏ –¥–ª—è s2t? –ê –¥–ª—è whisper?"

‚úÖ –û–¢–í–ï–¢:

1. –ü—Ä–∏ freeze_encoder():
   - Whisper: embed_tokens –û–°–¢–ê–Æ–¢–°–Ø –†–ê–ó–ú–û–†–û–ñ–ï–ù–ù–´–ú–ò ‚úÖ
   - Speech2Text: embed_tokens –û–°–¢–ê–Æ–¢–°–Ø –†–ê–ó–ú–û–†–û–ñ–ï–ù–ù–´–ú–ò ‚úÖ

2. –ü—Ä–∏ freeze_decoder():
   - Whisper: embed_tokens –ó–ê–ú–û–†–ê–ñ–ò–í–ê–Æ–¢–°–Ø ‚ùå
   - Speech2Text: embed_tokens –ó–ê–ú–û–†–ê–ñ–ò–í–ê–Æ–¢–°–Ø ‚ùå

3. Output projection (proj_out/lm_head):
   - Whisper: proj_out –í–°–ï–ì–î–ê –æ—Å—Ç–∞—ë—Ç—Å—è —Ä–∞–∑–º–æ—Ä–æ–∂–µ–Ω–Ω—ã–º ‚úÖ
   - Speech2Text: lm_head –í–°–ï–ì–î–ê –æ—Å—Ç–∞—ë—Ç—Å—è —Ä–∞–∑–º–æ—Ä–æ–∂–µ–Ω–Ω—ã–º ‚úÖ
   - –ü—Ä–∏—á–∏–Ω–∞: –æ–Ω–∏ –ù–ï —è–≤–ª—è—é—Ç—Å—è —á–∞—Å—Ç—å—é model.model.decoder

üìä –°–¢–†–£–ö–¢–£–†–ê –ú–û–î–ï–õ–ï–ô:

Whisper:
  model.model.encoder          ‚Üê freeze_encoder() –∑–∞—Ç—Ä–∞–≥–∏–≤–∞–µ—Ç
  model.model.decoder          ‚Üê freeze_decoder() –∑–∞—Ç—Ä–∞–≥–∏–≤–∞–µ—Ç
    ‚îî‚îÄ embed_tokens ‚ö†Ô∏è        ‚Üê –ß–ê–°–¢–¨ decoder, –∑–∞–º–µ—Ä–∑–∞–µ—Ç –ø—Ä–∏ freeze_decoder()!
    ‚îî‚îÄ embed_positions
    ‚îî‚îÄ layers[...]
  model.proj_out               ‚Üê –ù–ï –∑–∞—Ç—Ä–∞–≥–∏–≤–∞–µ—Ç—Å—è –Ω–∏ –æ–¥–Ω–∏–º –º–µ—Ç–æ–¥–æ–º

Speech2Text:
  model.model.encoder          ‚Üê freeze_encoder() –∑–∞—Ç—Ä–∞–≥–∏–≤–∞–µ—Ç
  model.model.decoder          ‚Üê freeze_decoder() –∑–∞—Ç—Ä–∞–≥–∏–≤–∞–µ—Ç
    ‚îî‚îÄ embed_tokens ‚ö†Ô∏è        ‚Üê –ß–ê–°–¢–¨ decoder, –∑–∞–º–µ—Ä–∑–∞–µ—Ç –ø—Ä–∏ freeze_decoder()!
    ‚îî‚îÄ embed_positions
    ‚îî‚îÄ layers[...]
  model.lm_head                ‚Üê –ù–ï –∑–∞—Ç—Ä–∞–≥–∏–≤–∞–µ—Ç—Å—è –Ω–∏ –æ–¥–Ω–∏–º –º–µ—Ç–æ–¥–æ–º

‚ö†Ô∏è –ö–†–ò–¢–ò–ß–ï–°–ö–û–ï –î–õ–Ø CROSS-LINGUAL TRANSFER:

–ù–∞—à –∫–æ–Ω—Ñ–∏–≥ s2t_cross_lingual.yaml:
  freeze_encoder: true    ‚úÖ –ü—Ä–∞–≤–∏–ª—å–Ω–æ - acoustic features —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã
  freeze_decoder: FALSE   ‚úÖ –í–ê–ñ–ù–û! –ò–Ω–∞—á–µ embed_tokens –∑–∞–º–µ—Ä–∑–Ω—É—Ç!

–ï—Å–ª–∏ freeze_decoder=true:
  ‚ùå embed_tokens –∑–∞–º—ë—Ä–∑–Ω—É—Ç
  ‚ùå –ù–æ–≤—ã–µ —Ä—É—Å—Å–∫–∏–µ —Ç–æ–∫–µ–Ω—ã –Ω–µ –æ–±—É—á–∞—Ç—Å—è
  ‚ùå –ú–æ–¥–µ–ª—å –Ω–µ —Å–º–æ–∂–µ—Ç –Ω–∞—É—á–∏—Ç—å—Å—è —Ä—É—Å—Å–∫–æ–º—É —è–∑—ã–∫—É

–ï—Å–ª–∏ freeze_decoder=false (—Ç–µ–∫—É—â–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞):
  ‚úÖ embed_tokens –æ–±—É—á–∞—é—Ç—Å—è
  ‚úÖ Decoder layers –æ–±—É—á–∞—é—Ç—Å—è
  ‚úÖ lm_head –æ–±—É—á–∞–µ—Ç—Å—è
  ‚úÖ –ú–æ–¥–µ–ª—å —É—á–∏—Ç—Å—è –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Ä—É—Å—Å–∫–∏–π —Ç–µ–∫—Å—Ç!
""")
