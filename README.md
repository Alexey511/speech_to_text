# Russian Speech-to-Text Fine-tuning Project

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch 2.5+](https://img.shields.io/badge/PyTorch-2.5+-red.svg)](https://pytorch.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

–ü—Ä–æ–µ–∫—Ç –¥–ª—è fine-tuning SOTA –º–æ–¥–µ–ª–µ–π speech-to-text –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞ Mozilla Common Voice 22.0. –ú–æ–¥—É–ª—å–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω—ã–º —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ–º, –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–º–∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏ –æ—Ü–µ–Ω–∫–∏ –∏ production-ready MLOps –ø—Ä–∞–∫—Ç–∏–∫–∞–º–∏.

## üéØ –¶–µ–ª—å –ø—Ä–æ–µ–∫—Ç–∞

–°–æ–∑–¥–∞–Ω–∏–µ –≤—ã—Å–æ–∫–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä—É—Å—Å–∫–æ–π —Ä–µ—á–∏ –ø—É—Ç–µ–º –¥–æ–æ–±—É—á–µ–Ω–∏—è –ø–µ—Ä–µ–¥–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (Whisper, Speech2Text) –Ω–∞ –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ Mozilla Common Voice 22.0 (~40 —á–∞—Å–æ–≤ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ —Ä—É—Å—Å–∫–æ–≥–æ –∞—É–¥–∏–æ).

## üöÄ –û—Å–Ω–æ–≤–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏

- **–ú–æ–¥—É–ª—å–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞** —Å –∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π (OmegaConf + YAML)
- **–ü–æ–¥–¥–µ—Ä–∂–∫–∞ SOTA –º–æ–¥–µ–ª–µ–π**:
  - OpenAI Whisper (tiny/base/small/medium/large)
  - Facebook Speech2Text —Å cross-lingual transfer
- **–ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏**: WER, CER, BLEU, MER, WIL, –¥–µ—Ç–∞–ª—å–Ω—ã–π error breakdown
- **–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –æ–±—É—á–µ–Ω–∏—è**: TensorBoard (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é), Weights & Biases (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
- **–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –¥–ª—è RTX 4070ti**: Mixed precision (FP16), gradient accumulation, memory management
- **–ü—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è**: Time/frequency-domain, SpecAugment, reverb (8+ —Ç–∏–ø–æ–≤ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–π)
- **Production-ready**: –û—Ç–¥–µ–ª—å–Ω—ã–µ —Å–∫—Ä–∏–ø—Ç—ã –¥–ª—è training/evaluation/inference, comprehensive testing
- **Advanced training**: Early stopping, multiple LR schedulers (linear, cosine, plateau, warmup-plateau-decay)
- **Flexible freezing**: Fine-grained control over encoder/decoder/embeddings freezing

## üìÅ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞

```
speech_to_text/
‚îú‚îÄ‚îÄ configs/                           # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã YAML
‚îÇ   ‚îú‚îÄ‚îÄ default.yaml                   # Whisper Small –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)
‚îÇ   ‚îú‚îÄ‚îÄ whisper_base.yaml              # Whisper Base –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
‚îÇ   ‚îú‚îÄ‚îÄ whisper_small.yaml             # Whisper Small –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
‚îÇ   ‚îú‚îÄ‚îÄ s2t_cross_lingual.yaml         # Speech2Text cross-lingual transfer
‚îÇ   ‚îî‚îÄ‚îÄ debug.yaml                     # Debug –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è (–±—ã—Å—Ç—Ä–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ)
‚îú‚îÄ‚îÄ data/                              # –û—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π Mozilla Common Voice 22.0
‚îÇ   ‚îî‚îÄ‚îÄ cv-corpus-22.0-2025-06-20/
‚îÇ       ‚îî‚îÄ‚îÄ ru/
‚îÇ           ‚îú‚îÄ‚îÄ train.tsv              # ~26K –æ–±—É—á–∞—é—â–∏—Ö –∑–∞–ø–∏—Å–µ–π
‚îÇ           ‚îú‚îÄ‚îÄ dev.tsv                # ~10K –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π
‚îÇ           ‚îú‚îÄ‚îÄ test.tsv               # ~10K —Ç–µ—Å—Ç–æ–≤—ã—Ö –∑–∞–ø–∏—Å–µ–π
‚îÇ           ‚îú‚îÄ‚îÄ clip_durations.tsv     # –ö—ç—à –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π (—É—Å–∫–æ—Ä–µ–Ω–∏–µ –∑–∞–≥—Ä—É–∑–∫–∏)
‚îÇ           ‚îî‚îÄ‚îÄ clips/                 # MP3 –∞—É–¥–∏–æ—Ñ–∞–π–ª—ã (~6.5GB)
‚îú‚îÄ‚îÄ experiments/                       # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤
‚îÇ   ‚îî‚îÄ‚îÄ <experiment_name>/
‚îÇ       ‚îú‚îÄ‚îÄ logs/                      # –õ–æ–≥–∏ –æ–±—É—á–µ–Ω–∏—è/–æ—Ü–µ–Ω–∫–∏
‚îÇ       ‚îú‚îÄ‚îÄ tensorboard/               # TensorBoard –ª–æ–≥–∏
‚îÇ       ‚îú‚îÄ‚îÄ checkpoint-XXX/            # –ß–µ–∫–ø–æ–∏–Ω—Ç—ã –º–æ–¥–µ–ª–∏
‚îÇ       ‚îú‚îÄ‚îÄ final_model/               # –§–∏–Ω–∞–ª—å–Ω–∞—è –æ–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å
‚îÇ       ‚îú‚îÄ‚îÄ config.yaml                # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞
‚îÇ       ‚îú‚îÄ‚îÄ test_results.json          # –ú–µ—Ç—Ä–∏–∫–∏ –Ω–∞ —Ç–µ—Å—Ç —Å–µ—Ç–µ
‚îÇ       ‚îî‚îÄ‚îÄ test_predictions.csv       # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –º–æ–¥–µ–ª–∏
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îú‚îÄ‚îÄ 01_eda.ipynb                   # –ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö (EDA)
‚îÇ   ‚îú‚îÄ‚îÄ 02_prepare_baseline_models.ipynb  # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ baseline –º–æ–¥–µ–ª–µ–π
‚îÇ   ‚îî‚îÄ‚îÄ debug.ipynb                    # Debug notebook
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ config.py                      # –ò–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è (OmegaConf)
‚îÇ   ‚îú‚îÄ‚îÄ data.py                        # –ü–∞–π–ø–ª–∞–π–Ω –¥–∞–Ω–Ω—ã—Ö (DataManager, Dataset, Collator)
‚îÇ   ‚îú‚îÄ‚îÄ models.py                      # –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –º–æ–¥–µ–ª–µ–π (Whisper, Speech2Text, Custom)
‚îÇ   ‚îú‚îÄ‚îÄ metrics.py                     # –ú–µ—Ç—Ä–∏–∫–∏ –æ—Ü–µ–Ω–∫–∏ (WER, CER, BLEU, MER, WIL)
‚îÇ   ‚îú‚îÄ‚îÄ processors.py                  # GPU-friendly feature extraction
‚îÇ   ‚îî‚îÄ‚îÄ utils.py                       # –£—Ç–∏–ª–∏—Ç—ã (–ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ, –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è, –ø—É—Ç–∏)
‚îú‚îÄ‚îÄ tests/                             # Comprehensive testing suite
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ conftest.py                    # Pytest fixtures (config, temp_dir)
‚îÇ   ‚îú‚îÄ‚îÄ test_config.py                 # –¢–µ—Å—Ç—ã –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
‚îÇ   ‚îú‚îÄ‚îÄ test_data_manager.py           # –¢–µ—Å—Ç—ã DataManager
‚îÇ   ‚îú‚îÄ‚îÄ test_dataloader.py             # –¢–µ—Å—Ç—ã DataLoader
‚îÇ   ‚îú‚îÄ‚îÄ test_metrics.py                # –¢–µ—Å—Ç—ã –º–µ—Ç—Ä–∏–∫
‚îÇ   ‚îú‚îÄ‚îÄ test_models.py                 # –¢–µ—Å—Ç—ã –º–æ–¥–µ–ª–µ–π
‚îÇ   ‚îú‚îÄ‚îÄ test_training.py               # –¢–µ—Å—Ç—ã –æ–±—É—á–µ–Ω–∏—è
‚îÇ   ‚îú‚îÄ‚îÄ test_utils.py                  # –¢–µ—Å—Ç—ã —É—Ç–∏–ª–∏—Ç
‚îÇ   ‚îú‚îÄ‚îÄ dataloader_speed.py            # –ë–µ–Ω—á–º–∞—Ä–∫ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ DataLoader
‚îÇ   ‚îî‚îÄ‚îÄ .test_tmp/                     # –í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã —Ç–µ—Å—Ç–æ–≤ (auto-cleanup)
‚îú‚îÄ‚îÄ .gitignore                         # Git ignore (data/, experiments/, .test_tmp/)
‚îú‚îÄ‚îÄ requirements.txt                   # Python –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
‚îú‚îÄ‚îÄ setup_check.py                     # –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–∫—Ä—É–∂–µ–Ω–∏—è –∏ –¥–∞—Ç–∞—Å–µ—Ç–∞
‚îú‚îÄ‚îÄ train.py                           # –û—Å–Ω–æ–≤–Ω–æ–π —Å–∫—Ä–∏–ø—Ç –æ–±—É—á–µ–Ω–∏—è
‚îú‚îÄ‚îÄ evaluation.py                      # –ê–≤—Ç–æ–Ω–æ–º–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–µ–π
‚îú‚îÄ‚îÄ inference.py                       # Production –∏–Ω—Ñ–µ—Ä–µ–Ω—Å (single/batch)
‚îú‚îÄ‚îÄ run_experiments.py                 # –û—Ä–∫–µ—Å—Ç—Ä–∞—Ü–∏—è –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤
‚îú‚îÄ‚îÄ CLAUDE.md                          # –†—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –¥–ª—è Claude Code
‚îî‚îÄ‚îÄ README.md                          # –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è
```

## üõ† –£—Å—Ç–∞–Ω–æ–≤–∫–∞

### –°–∏—Å—Ç–µ–º–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è

- **OS**: Windows 10/11, Linux, macOS
- **Python**: 3.8+
- **GPU**: RTX 4070ti –∏–ª–∏ –∞–Ω–∞–ª–æ–≥–∏—á–Ω–∞—è (–º–∏–Ω–∏–º—É–º 8GB VRAM –¥–ª—è Whisper Small, 12GB+ –¥–ª—è Medium)
- **RAM**: 16GB+ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è
- **–î–∏—Å–∫**: 50GB+ —Å–≤–æ–±–æ–¥–Ω–æ–≥–æ –º–µ—Å—Ç–∞ (–¥–∞—Ç–∞—Å–µ—Ç ~6.5GB + —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã ~10-30GB)

### –£—Å—Ç–∞–Ω–æ–≤–∫–∞ —Å Conda (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)

–ü—Ä–æ–µ–∫—Ç –∏—Å–ø–æ–ª—å–∑—É–µ—Ç conda –æ–∫—Ä—É–∂–µ–Ω–∏–µ `basenn` –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—è–º–∏:

```bash
# –°–æ–∑–¥–∞–Ω–∏–µ conda –æ–∫—Ä—É–∂–µ–Ω–∏—è
conda create -n basenn python=3.10 -y
conda activate basenn

# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ PyTorch —Å CUDA support
conda install -n basenn pytorch==2.5.1 torchvision==0.20.1 torchaudio==2.5.1 pytorch-cuda=12.1 -c pytorch -c nvidia -y

# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –æ—Å–Ω–æ–≤–Ω—ã—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π —á–µ—Ä–µ–∑ conda
conda install -n basenn -c conda-forge pandas numpy scipy matplotlib seaborn plotly tqdm pyyaml rich ffmpeg -y

# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏
conda install -n basenn -c conda-forge mypy ruff pytest jiwer -y

# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π —á–µ—Ä–µ–∑ pip (—Ç–æ–ª—å–∫–æ —Ç–µ, —á—Ç–æ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã –≤ conda)
conda run -n basenn pip install -r requirements.txt
```

### –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–∞—è —É—Å—Ç–∞–Ω–æ–≤–∫–∞ (pip/venv)

```bash
# –ö–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è
git clone <repository_url>
cd speech_to_text

# –°–æ–∑–¥–∞–Ω–∏–µ –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–≥–æ –æ–∫—Ä—É–∂–µ–Ω–∏—è
python -m venv venv
source venv/bin/activate  # Linux/Mac
# –∏–ª–∏
venv\Scripts\activate     # Windows

# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
pip install -r requirements.txt

# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ ffmpeg (–¥–ª—è MP3 support)
# Windows: —Å–∫–∞—á–∞—Ç—å —Å https://ffmpeg.org/download.html
# Linux: sudo apt-get install ffmpeg
# macOS: brew install ffmpeg
```

### –ü—Ä–æ–≤–µ—Ä–∫–∞ —É—Å—Ç–∞–Ω–æ–≤–∫–∏

```bash
# –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–∫—Ä—É–∂–µ–Ω–∏—è
python setup_check.py

# –ò–ª–∏ –≤—Ä—É—á–Ω—É—é:
python -c "import torch; print(f'PyTorch: {torch.__version__}, CUDA: {torch.cuda.is_available()}')"
```

**–û–∂–∏–¥–∞–µ–º—ã–π –≤—ã–≤–æ–¥:**
```
‚úì PyTorch: 2.5.1, CUDA: True
‚úì CUDA device: NVIDIA GeForce RTX 4070 Ti
‚úì Transformers: 4.57.0
‚úì Dataset found: data/cv-corpus-22.0-2025-06-20/ru/
```

## üèÉ‚Äç‚ôÇÔ∏è –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç

### 1. –°–∫–∞—á–∏–≤–∞–Ω–∏–µ –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞ Mozilla Common Voice 22.0

**üì• –°–∫–∞—á–∞–π—Ç–µ –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç:**

1. **–ü–µ—Ä–µ–π–¥–∏—Ç–µ –Ω–∞ –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π —Å–∞–π—Ç:** https://commonvoice.mozilla.org/en/datasets
2. **–ù–∞–π–¥–∏—Ç–µ Russian (ru)** –≤ —Å–ø–∏—Å–∫–µ —è–∑—ã–∫–æ–≤
3. **–°–∫–∞—á–∞–π—Ç–µ Common Voice Corpus 22.0** (—Ñ–∞–π–ª ~6.5GB)
4. **–†–∞—Å–ø–∞–∫—É–π—Ç–µ –∞—Ä—Ö–∏–≤** –≤ –ø–∞–ø–∫—É –ø—Ä–æ–µ–∫—Ç–∞:

```bash
# –°–æ–∑–¥–∞–π—Ç–µ –ø–∞–ø–∫—É –¥–ª—è –¥–∞–Ω–Ω—ã—Ö (–µ—Å–ª–∏ –µ—â–µ –Ω–µ—Ç)
mkdir -p data

# –†–∞—Å–ø–∞–∫—É–π—Ç–µ —Å–∫–∞—á–∞–Ω–Ω—ã–π –∞—Ä—Ö–∏–≤ cv-corpus-22.0-2025-06-20-ru.tar.gz
# –≤ –ø–∞–ø–∫—É data/ 
# –î–æ–ª–∂–Ω–∞ –ø–æ–ª—É—á–∏—Ç—å—Å—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞: data/cv-corpus-22.0-2025-06-20/ru/
```

**‚úÖ –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞:**
- üõ°Ô∏è **–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å** - –ø—Ä—è–º–æ –æ—Ç Mozilla Foundation
- üìà **–ê–∫—Ç—É–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ** - Common Voice 22.0 (—Å–∞–º–∞—è —Å–≤–µ–∂–∞—è –≤–µ—Ä—Å–∏—è)
- üéØ **–ö–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –∑–∞–ø–∏—Å–∏** - –ø—Ä–æ–≤–µ—Ä–µ–Ω–Ω—ã–µ –∏ –≤–∞–ª–∏–¥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ
- ‚ö° **250+ —á–∞—Å–æ–≤** —Ä—É—Å—Å–∫–æ–≥–æ –∞—É–¥–∏–æ –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–≥–æ fine-tuning

### 2. –ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö

```bash
jupyter notebook notebooks/01_eda.ipynb
```

### 3. –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏

**–û–±—É—á–µ–Ω–∏–µ —Å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é (Whisper Small):**
```bash
python train.py
```

**–û–±—É—á–µ–Ω–∏–µ —Å —É–∫–∞–∑–∞–Ω–Ω—ã–º –∫–æ–Ω—Ñ–∏–≥–æ–º:**
```bash
# Whisper Base
python train.py --config configs/whisper_base.yaml

# Speech2Text cross-lingual
python train.py --config configs/s2t_cross_lingual.yaml

# –° –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º –∏–º–µ–Ω–∏ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞
python train.py --config configs/whisper_small.yaml --experiment-name whisper_small_v2
```

**Debug —Ä–µ–∂–∏–º (–±—ã—Å—Ç—Ä–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å —Å–æ–∫—Ä–∞—â–µ–Ω–Ω—ã–º–∏ —ç–ø–æ—Ö–∞–º–∏):**
```bash
python train.py --debug --no-wandb
```

**–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ:** –í—Å–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏ –∏ –æ–±—É—á–µ–Ω–∏—è –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞—é—Ç—Å—è —á–µ—Ä–µ–∑ YAML –∫–æ–Ω—Ñ–∏–≥–∏ –≤ `configs/`. CLI –∞—Ä–≥—É–º–µ–Ω—Ç—ã –ø—Ä–µ–¥–Ω–∞–∑–Ω–∞—á–µ–Ω—ã —Ç–æ–ª—å–∫–æ –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–º (`--config`, `--experiment-name`, `--debug`, `--no-wandb`).

### 4. –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏

**–û—Ü–µ–Ω–∫–∞ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ –Ω–∞ test set:**
```bash
python evaluation.py --model-path experiments/whisper_ru_cv22_finetune/final_model
```

**–û—Ü–µ–Ω–∫–∞ —Å –¥–µ—Ç–∞–ª—å–Ω—ã–º –∞–Ω–∞–ª–∏–∑–æ–º –æ—à–∏–±–æ–∫:**
```bash
python evaluation.py --model-path experiments/whisper_ru_cv22_finetune/final_model --detailed-analysis --save-predictions
```

**–û—Ü–µ–Ω–∫–∞ baseline –º–æ–¥–µ–ª–∏ –±–µ–∑ fine-tuning:**
```bash
python evaluation.py --model-path openai/whisper-small --config configs/default.yaml
```

### 5. –ò–Ω—Ñ–µ—Ä–µ–Ω—Å

**–ò–Ω—Ñ–µ—Ä–µ–Ω—Å –æ–¥–Ω–æ–≥–æ –∞—É–¥–∏–æ—Ñ–∞–π–ª–∞:**
```bash
python inference.py --model-path experiments/whisper_ru_cv22_finetune/final_model --input audio.mp3
```

**–ü–∞–∫–µ—Ç–Ω—ã–π –∏–Ω—Ñ–µ—Ä–µ–Ω—Å (–¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è):**
```bash
python inference.py --model-path experiments/whisper_ru_cv22_finetune/final_model --input audio_folder/ --output results.json --format json
```

### 6. –ó–∞–ø—É—Å–∫ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤

**–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –º–æ–¥–µ–ª–µ–π:**
```bash
python run_experiments.py --experiments whisper_small whisper_base s2t_cross_lingual
```

**Debug —Ä–µ–∂–∏–º –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è:**
```bash
python run_experiments.py --debug
```

## üìä –†–∞–±–æ—Ç–∞ —Å –¥–∞–Ω–Ω—ã–º–∏

### üìÅ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ Common Voice 22.0

–ü–æ—Å–ª–µ —Ä–∞—Å–ø–∞–∫–æ–≤–∫–∏ –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å:

```
data/
‚îî‚îÄ‚îÄ cv-corpus-22.0-2025-06-20/
    ‚îî‚îÄ‚îÄ ru/
        ‚îú‚îÄ‚îÄ train.tsv           # ~26K –æ–±—É—á–∞—é—â–∏—Ö –∑–∞–ø–∏—Å–µ–π
        ‚îú‚îÄ‚îÄ dev.tsv             # ~10K –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π  
        ‚îú‚îÄ‚îÄ test.tsv            # ~10K —Ç–µ—Å—Ç–æ–≤—ã—Ö –∑–∞–ø–∏—Å–µ–π
        ‚îú‚îÄ‚îÄ validated.tsv       # –í—Å–µ –≤–∞–ª–∏–¥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∑–∞–ø–∏—Å–∏
        ‚îî‚îÄ‚îÄ clips/              # üéµ –ê—É–¥–∏–æ—Ñ–∞–π–ª—ã (~6.5GB)
            ‚îú‚îÄ‚îÄ common_voice_ru_*.mp3
            ‚îî‚îÄ‚îÄ ...
```

### üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞

–ü—Ä–æ–≤–µ—Ä—å—Ç–µ —á—Ç–æ –¥–∞—Ç–∞—Å–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω —Å –ø–æ–º–æ—â—å—é pytest:

```bash
# –ó–∞–ø—É—Å—Ç–∏—Ç–µ –≤—Å–µ —Ç–µ—Å—Ç—ã
pytest tests/ -v

# –ò–ª–∏ —Ç–æ–ª—å–∫–æ —Ç–µ—Å—Ç—ã DataManager  
pytest tests/test_data_manager.py -v

# –¢–µ—Å—Ç—ã —Å –ø–æ–¥—Ä–æ–±–Ω—ã–º –≤—ã–≤–æ–¥–æ–º
pytest tests/test_data_manager.py::TestDataManager::test_dataset_info -v -s
```

**–û–∂–∏–¥–∞–µ–º—ã–π –≤—ã–≤–æ–¥:**
- ‚úÖ test_dataset_availability PASSED
- ‚úÖ test_dataset_info PASSED  
- ‚úÖ test_load_train_dataset PASSED
- ‚úÖ üìä Dataset stats: ~47,000 samples, ~38 hours

### ‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö

–í –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ `configs/default.yaml`:

```yaml
data:
  language: "ru"                    # –†—É—Å—Å–∫–∏–π —è–∑—ã–∫
  validation_split: "dev"           # Common Voice –∏—Å–ø–æ–ª—å–∑—É–µ—Ç 'dev' 
  filter_by_duration: false        # –§–∏–ª—å—Ç—Ä–æ–≤–∞—Ç—å –ø–æ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
  max_duration: 30.0               # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å (—Å–µ–∫)
  min_duration: 0.5                # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å (—Å–µ–∫)
  sample_rate: 16000               # –ß–∞—Å—Ç–æ—Ç–∞ –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏
```

### üìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞

- **–û–±—â–∏–π –æ–±—ä–µ–º:** ~38 —á–∞—Å–æ–≤ —Ä—É—Å—Å–∫–æ–≥–æ –∞—É–¥–∏–æ
- **–ö–∞—á–µ—Å—Ç–≤–æ:** –ü—Ä–æ–≤–µ—Ä–µ–Ω–Ω—ã–µ –∑–∞–ø–∏—Å–∏ —Å up_votes > down_votes  
- **–§–æ—Ä–º–∞—Ç:** 16kHz MP3 + TSV –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
- **–ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å:** –û—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π Mozilla Foundation

## ‚öôÔ∏è –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è

–ü—Ä–æ–µ–∫—Ç –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫—É—é —Å–∏—Å—Ç–µ–º—É –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ **OmegaConf** —Å YAML —Ñ–∞–π–ª–∞–º–∏. –í—Å–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏, –æ–±—É—á–µ–Ω–∏—è –∏ –¥–∞–Ω–Ω—ã—Ö –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞—é—Ç—Å—è —á–µ—Ä–µ–∑ –∫–æ–Ω—Ñ–∏–≥–∏ –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ `configs/`.

### –û—Å–Ω–æ–≤–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã (configs/default.yaml)

```yaml
# –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç
experiment:
  output_dir: "experiments"
  experiment_name: "whisper_ru_cv22_finetune"
  seed: 42

# –ú–æ–¥–µ–ª—å
model:
  model_name: "openai/whisper-small"
  model_type: "whisper"

  # –°—Ç—Ä–∞—Ç–µ–≥–∏—è –∑–∞–º–æ—Ä–æ–∑–∫–∏ —Å–ª–æ–µ–≤
  freeze_feature_encoder: true    # –ó–∞–º–æ—Ä–æ–∑–∏—Ç—å feature encoder
  freeze_encoder: true            # –ó–∞–º–æ—Ä–æ–∑–∏—Ç—å encoder
  freeze_decoder: false           # Decoder –æ–±—É—á–∞–µ–º—ã–π (language-specific)

  # Fine-grained –∫–æ–Ω—Ç—Ä–æ–ª—å
  unfreeze_embed_tokens: false    # –†–∞–∑–º–æ—Ä–æ–∑–∏—Ç—å embeddings –¥–µ–∫–æ–¥–µ—Ä–∞
  unfreeze_lm_head: false         # –†–∞–∑–º–æ—Ä–æ–∑–∏—Ç—å output projection

  # Dropout (–í–ê–ñ–ù–û: –¥–ª—è Whisper —Å—Ç–∞–≤–∏—Ç—å 0.0!)
  activation_dropout: 0.0
  attention_dropout: 0.0
  dropout: 0.0

# –û–±—É—á–µ–Ω–∏–µ
training:
  num_train_epochs: 10
  train_batch_size: 8
  eval_batch_size: 8
  gradient_accumulation_steps: 2
  learning_rate: 1e-4
  weight_decay: 0.01
  fp16: true  # Mixed precision –¥–ª—è RTX 4070ti

  # Learning rate scheduler
  scheduler_name: "linear"  # linear, cosine, reduce_on_plateau, onecycle, warmup_plateau_decay

  # Early stopping
  use_early_stopping: true
  early_stopping_patience: 3
  early_stopping_threshold: 0.01

# –î–∞–Ω–Ω—ã–µ
data:
  language: "ru"
  task: "transcribe"
  data_dir: "data"
  dataset_path: "cv-corpus-22.0-2025-06-20/ru"
  sample_rate: 16000

  # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
  filter_by_duration: true
  max_duration: 30.0
  min_duration: 0.2

  # –ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è
  augmentation:
    enabled: true
    add_noise: true
    speed_perturbation: true
    pitch_shift: true
    spec_augment: true
    reverb: true
    # ... –∏ –¥—Ä—É–≥–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã

# –û—Ü–µ–Ω–∫–∞
evaluation:
  batch_size: 16
  calculate_wer: true
  calculate_cer: true
  calculate_bleu: false
  num_beams: 1

  # Anti-repetition (–¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –∑–∞—Ü–∏–∫–ª–∏–≤–∞–Ω–∏—è)
  repetition_penalty: 1.2
  no_repeat_ngram_size: 3

# –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
logging:
  use_wandb: false
  wandb_project: "speech-to-text-ru"
  log_level: "INFO"
  report_to: ["tensorboard", "wandb"]
```

### –î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏

- **`default.yaml`** - Whisper Small (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–ª—è –Ω–∞—á–∞–ª–∞)
- **`whisper_base.yaml`** - Whisper Base (–ª–µ–≥—á–µ, –±—ã—Å—Ç—Ä–µ–µ)
- **`whisper_small.yaml`** - Whisper Small (–±–∞–ª–∞–Ω—Å –∫–∞—á–µ—Å—Ç–≤–∞ –∏ —Å–∫–æ—Ä–æ—Å—Ç–∏)
- **`s2t_cross_lingual.yaml`** - Speech2Text cross-lingual transfer (English‚ÜíRussian)
- **`debug.yaml`** - Debug –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è (2 —ç–ø–æ—Ö–∏, —Å–æ–∫—Ä–∞—â–µ–Ω–Ω—ã–µ —à–∞–≥–∏)

## üîß –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ –º–æ–¥–µ–ª–∏

### 1. OpenAI Whisper (Multilingual)
Encoder-decoder –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π 99 —è–∑—ã–∫–æ–≤. –û–±—É—á–µ–Ω—ã –Ω–∞ 680K —á–∞—Å–æ–≤ –∞—É–¥–∏–æ.

- **`openai/whisper-tiny`** (39M –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤) - —Å–∞–º–∞—è –±—ã—Å—Ç—Ä–∞—è
- **`openai/whisper-base`** (74M –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤) - –±–∞–ª–∞–Ω—Å —Å–∫–æ—Ä–æ—Å—Ç–∏ –∏ –∫–∞—á–µ—Å—Ç–≤–∞
- **`openai/whisper-small`** (244M –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤) - **—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è** –¥–ª—è fine-tuning
- **`openai/whisper-medium`** (769M –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤) - –≤—ã—Å–æ–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ
- **`openai/whisper-large`** (1550M –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤) - –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ (—Ç—Ä–µ–±—É–µ—Ç 16GB+ VRAM)

**–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:**
```yaml
model:
  model_name: "openai/whisper-small"
  model_type: "whisper"
```

### 2. Facebook Speech2Text (Cross-lingual Transfer)
Encoder-decoder –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –¥–ª—è ASR –∏ speech translation.

- **`facebook/s2t-small-librispeech-asr`** (~31M –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤, English)
  - **–°—Ç—Ä–∞—Ç–µ–≥–∏—è:** Fine-tuning –∞–Ω–≥–ª–∏–π—Å–∫–æ–π –º–æ–¥–µ–ª–∏ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —Ä—É—Å—Å–∫–∏–º —á–µ—Ä–µ–∑ cross-lingual transfer
  - –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –º–Ω–æ–≥–æ—è–∑—ã—á–Ω—ã–π —Ç–æ–∫–µ–Ω–∞–π–∑–µ—Ä `facebook/s2t-medium-mustc-multilingual-st`
  - –¢—Ä–µ–±—É–µ—Ç unfreezing decoder embeddings –¥–ª—è –∞–¥–∞–ø—Ç–∞—Ü–∏–∏ –∫ –Ω–æ–≤–æ–º—É —Å–ª–æ–≤–∞—Ä—é

**–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:**
```yaml
model:
  model_name: "facebook/s2t-small-librispeech-asr"
  model_type: "speech2text"
  tokenizer_name_or_path: "facebook/s2t-medium-mustc-multilingual-st"
  unfreeze_embed_tokens: true  # –ö—Ä–∏—Ç–∏—á–Ω–æ –¥–ª—è cross-lingual transfer!
```


**–°—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞:**

| –ú–æ–¥–µ–ª—å | –ü–∞—Ä–∞–º–µ—Ç—Ä—ã | VRAM | –°–∫–æ—Ä–æ—Å—Ç—å | –ö–∞—á–µ—Å—Ç–≤–æ (WER ‚Üì) | –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è |
|--------|-----------|------|----------|------------------|--------------|
| Whisper Tiny | 39M | ~2GB | ‚ö°‚ö°‚ö°‚ö°‚ö° | ~25-30% | Quick prototyping |
| Whisper Base | 74M | ~3GB | ‚ö°‚ö°‚ö°‚ö° | ~20-25% | Fast inference |
| **Whisper Small** | 244M | ~5GB | ‚ö°‚ö°‚ö° | **~15-20%** | **‚úÖ –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è** |
| Whisper Medium | 769M | ~10GB | ‚ö°‚ö° | ~12-15% | High quality |
| Speech2Text Small | 31M | ~2GB | ‚ö°‚ö°‚ö°‚ö° | ~25-30%* | Cross-lingual experiments |
| Custom Model | ~50M | ~3GB | ‚ö°‚ö°‚ö°‚ö° | ~30-35%* | Research |

*–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–∞ —Ä—É—Å—Å–∫–æ–º –ø–æ—Å–ª–µ fine-tuning (baseline –±–µ–∑ fine-tuning —Ö—É–∂–µ)

## üìä –ú–µ—Ç—Ä–∏–∫–∏ –∏ –æ—Ü–µ–Ω–∫–∞

–ü—Ä–æ–µ–∫—Ç –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –Ω–∞–±–æ—Ä –º–µ—Ç—Ä–∏–∫ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–µ–π ASR:

### –û—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏

- **WER (Word Error Rate)** - –æ—Å–Ω–æ–≤–Ω–∞—è –º–µ—Ç—Ä–∏–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è
  - –ò–∑–º–µ—Ä—è–µ—Ç –ø—Ä–æ—Ü–µ–Ω—Ç –æ—à–∏–±–æ—á–Ω–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã—Ö —Å–ª–æ–≤
  - –§–æ—Ä–º—É–ª–∞: `(Substitutions + Deletions + Insertions) / Total Words √ó 100%`
  - –†–µ–∞–ª–∏–∑–∞—Ü–∏—è: –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ `jiwer`

- **CER (Character Error Rate)** - –¥–µ—Ç–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –Ω–∞ —É—Ä–æ–≤–Ω–µ —Å–∏–º–≤–æ–ª–æ–≤
  - –ü–æ–ª–µ–∑–Ω–∞ –¥–ª—è —è–∑—ã–∫–æ–≤ —Å –¥–ª–∏–Ω–Ω—ã–º–∏ —Å–ª–æ–≤–∞–º–∏ –∏–ª–∏ —Å–ª–æ–∂–Ω–æ–π –º–æ—Ä—Ñ–æ–ª–æ–≥–∏–µ–π
  - –§–æ—Ä–º—É–ª–∞: –∞–Ω–∞–ª–æ–≥–∏—á–Ω–∞ WER, –Ω–æ –Ω–∞ —É—Ä–æ–≤–Ω–µ —Å–∏–º–≤–æ–ª–æ–≤

- **BLEU (Bilingual Evaluation Understudy)** - –º–µ—Ç—Ä–∏–∫–∞ –∏–∑ –º–∞—à–∏–Ω–Ω–æ–≥–æ –ø–µ—Ä–µ–≤–æ–¥–∞
  - –û—Ü–µ–Ω–∏–≤–∞–µ—Ç n-gram overlap –º–µ–∂–¥—É –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ–º –∏ —ç—Ç–∞–ª–æ–Ω–æ–º
  - –†–µ–∞–ª–∏–∑–∞—Ü–∏—è: HuggingFace `evaluate` –±–∏–±–ª–∏–æ—Ç–µ–∫–∞

- **MER (Match Error Rate)** - –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–∞—è –º–µ—Ç—Ä–∏–∫–∞ —Ç–æ—á–Ω–æ—Å—Ç–∏ —Å–ª–æ–≤
  - –ü–æ—Ö–æ–∂–∞ –Ω–∞ WER, –Ω–æ –ø–æ-–¥—Ä—É–≥–æ–º—É –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∑–∞–º–µ–Ω—ã

- **WIL (Word Information Lost)** - –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω–∞—è –º–µ—Ç—Ä–∏–∫–∞ –ø–æ—Ç–µ—Ä—å
  - –£—á–∏—Ç—ã–≤–∞–µ—Ç –Ω–µ —Ç–æ–ª—å–∫–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ, –Ω–æ –∏ "–≤–µ—Å" –æ—à–∏–±–æ–∫

### –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –æ—à–∏–±–æ–∫

–°–∫—Ä–∏–ø—Ç `evaluation.py` —Å —Ñ–ª–∞–≥–æ–º `--detailed-analysis` –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç:

- **Error breakdown** –ø–æ —Ç–∏–ø–∞–º:
  - Substitutions (–∑–∞–º–µ–Ω—ã): –∫–∞–∫–∏–µ —Å–ª–æ–≤–∞ –±—ã–ª–∏ –∑–∞–º–µ–Ω–µ–Ω—ã
  - Deletions (–ø—Ä–æ–ø—É—Å–∫–∏): –∫–∞–∫–∏–µ —Å–ª–æ–≤–∞ –Ω–µ –±—ã–ª–∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω—ã
  - Insertions (–¥–æ–±–∞–≤–ª–µ–Ω–∏—è): –ª–∏—à–Ω–∏–µ —Å–ª–æ–≤–∞ –≤ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–∏
  - Hits (–ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ): –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–µ —Å–ª–æ–≤–∞

- **–ê–Ω–∞–ª–∏–∑ –ø–æ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∞—É–¥–∏–æ**:
  - WER/CER –¥–ª—è –∫–æ—Ä–æ—Ç–∫–∏—Ö (<5s), —Å—Ä–µ–¥–Ω–∏—Ö (5-15s), –¥–ª–∏–Ω–Ω—ã—Ö (>15s) –∑–∞–ø–∏—Å–µ–π
  - –í—ã—è–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º —Å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–º–∏ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—è–º–∏

- **–ê–Ω–∞–ª–∏–∑ –ø–æ –¥–ª–∏–Ω–µ —Ç–µ–∫—Å—Ç–∞**:
  - –ú–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –∫–æ—Ä–æ—Ç–∫–∏—Ö, —Å—Ä–µ–¥–Ω–∏—Ö, –¥–ª–∏–Ω–Ω—ã—Ö —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–æ–≤
  - –ü–æ–Ω–∏–º–∞–Ω–∏–µ –≤–ª–∏—è–Ω–∏—è —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ —Ç–µ–∫—Å—Ç–∞

### –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ

**–ë–∞–∑–æ–≤–∞—è –æ—Ü–µ–Ω–∫–∞:**
```bash
python evaluation.py --model-path experiments/whisper_ru_cv22_finetune/final_model
```

**–° –¥–µ—Ç–∞–ª—å–Ω—ã–º –∞–Ω–∞–ª–∏–∑–æ–º:**
```bash
python evaluation.py \
    --model-path experiments/whisper_ru_cv22_finetune/final_model \
    --detailed-analysis \
    --save-predictions
```

**–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Ü–µ–Ω–∫–∏** —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –≤ `experiments/<model_name>_evaluation/`:
- `test_results.json` - –æ—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ (WER, CER, BLEU, MER, WIL)
- `test_predictions.csv` - –≤—Å–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –º–æ–¥–µ–ª–∏
- `test_detailed_analysis.json` - –¥–µ—Ç–∞–ª—å–Ω—ã–π breakdown –æ—à–∏–±–æ–∫ (–µ—Å–ª–∏ `--detailed-analysis`)
- TensorBoard –ª–æ–≥–∏ —Å–æ –≤—Å–µ–º–∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏

## üéõ –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥

–ü—Ä–æ–µ–∫—Ç –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –¥–≤–∞ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –æ–±—É—á–µ–Ω–∏—è:

### TensorBoard (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é, –≤—Å–µ–≥–¥–∞ –≤–∫–ª—é—á–µ–Ω)

TensorBoard –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ª–æ–≥–∏—Ä—É–µ—Ç –≤—Å–µ –º–µ—Ç—Ä–∏–∫–∏ –≤–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è –∏ –æ—Ü–µ–Ω–∫–∏.

**–ó–∞–ø—É—Å–∫ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è:**
```bash
# –î–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞
tensorboard --logdir experiments/whisper_ru_cv22_finetune/tensorboard

# –î–ª—è –≤—Å–µ—Ö —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤
tensorboard --logdir experiments
```

**–ó–∞–ø—É—Å–∫ –¥–ª—è –æ—Ü–µ–Ω–∫–∏:**
```bash
tensorboard --logdir experiments/whisper-small-no-finetune_evaluation
```

**–î–æ—Å—Ç—É–ø–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏:**
- Training loss –ø–æ —à–∞–≥–∞–º
- Evaluation metrics (WER, CER, BLEU) –ø–æ —ç–ø–æ—Ö–∞–º
- Learning rate schedule
- Gradient norms (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–æ)
- Error breakdown (substitutions, deletions, insertions, hits)

### Weights & Biases (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)

WandB –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –æ–±–ª–∞—á–Ω—ã–π –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ —Å –ø—Ä–æ–¥–≤–∏–Ω—É—Ç–æ–π –∞–Ω–∞–ª–∏—Ç–∏–∫–æ–π.

**–ù–∞—Å—Ç—Ä–æ–π–∫–∞:**
```bash
# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ (–µ—Å–ª–∏ –µ—â–µ –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω)
conda run -n basenn pip install wandb

# –õ–æ–≥–∏–Ω
wandb login

# –í–∫–ª—é—á–∏—Ç—å –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
```

**–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –≤ `configs/default.yaml`:**
```yaml
logging:
  use_wandb: true
  wandb_project: "speech-to-text-ru"
  wandb_entity: "your-username"  # –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ
  report_to: ["tensorboard", "wandb"]
```

**–û—Ç–∫–ª—é—á–µ–Ω–∏–µ WandB:**
```bash
# –ß–µ—Ä–µ–∑ CLI —Ñ–ª–∞–≥
python train.py --no-wandb

# –ò–ª–∏ –≤ –∫–æ–Ω—Ñ–∏–≥–µ
logging:
  use_wandb: false
```

**–ß—Ç–æ –ª–æ–≥–∏—Ä—É–µ—Ç—Å—è –≤ WandB:**
- –í—Å–µ –º–µ—Ç—Ä–∏–∫–∏ –∏–∑ TensorBoard
- System metrics (GPU utilization, memory)
- Hyperparameters
- Model artifacts (—á–µ–∫–ø–æ–∏–Ω—Ç—ã)
- –ü—Ä–∏–º–µ—Ä—ã –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π (—Ç–∞–±–ª–∏—Ü—ã)
- –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤

## üß™ –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã


### –†—É—á–Ω–æ–π –∑–∞–ø—É—Å–∫ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤

**Whisper Small (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è):**
```bash
python train.py --config configs/whisper_small.yaml --experiment-name whisper_small_ru
```

**Whisper Base (–±—ã—Å—Ç—Ä–µ–µ, –º–µ–Ω—å—à–µ VRAM):**
```bash
python train.py --config configs/whisper_base.yaml --experiment-name whisper_base_ru
```

**Speech2Text Cross-lingual (English‚ÜíRussian):**
```bash
python train.py --config configs/s2t_cross_lingual.yaml --experiment-name s2t_xlingual_ru
```

**Custom model (—ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞):**
```bash
python train.py --config configs/custom_model.yaml --experiment-name custom_baseline
```

### –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

**–ß–µ—Ä–µ–∑ TensorBoard:**
```bash
# –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤
tensorboard --logdir experiments
```

**–ü—Ä–æ–≥—Ä–∞–º–º–Ω—ã–π –∞–Ω–∞–ª–∏–∑:**
```python
from src.utils import ExperimentTracker
import json

# –ó–∞–≥—Ä—É–∑–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞
tracker = ExperimentTracker("experiments/whisper_small_ru")

# –ü–æ—Å—Ç—Ä–æ–∏—Ç—å –≥—Ä–∞—Ñ–∏–∫–∏ –æ–±—É—á–µ–Ω–∏—è
tracker.plot_training_curves()

# –ó–∞–≥—Ä—É–∑–∏—Ç—å –º–µ—Ç—Ä–∏–∫–∏
with open("experiments/whisper_small_ru/test_results.json") as f:
    results = json.load(f)
    print(f"WER: {results['wer']:.2f}%")
    print(f"CER: {results['cer']:.2f}%")
```

### –í–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

–î–ª—è –æ–±–µ—Å–ø–µ—á–µ–Ω–∏—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤:

1. **–§–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π seed** –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏:
   ```yaml
   experiment:
     seed: 42
   ```

2. **–í–µ—Ä—Å–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π** —á–µ—Ä–µ–∑ `requirements.txt`

3. **–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏** –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞:
   - `experiments/<experiment_name>/config.yaml`

4. **Git commit hash** –ª–æ–≥–∏—Ä—É–µ—Ç—Å—è –≤ WandB (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω)

## ‚ö†Ô∏è –í–∞–∂–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã –∏ —Ä–µ—à–µ–Ω–∏—è

### –ö–†–ò–¢–ò–ß–ï–°–ö–û–ï: –í—ã—Å–æ–∫–∏–π loss –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ (Dropout sensitivity)

**‚ö†Ô∏è Whisper –º–æ–¥–µ–ª–∏ –ö–†–ê–ô–ù–ï —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã –∫ dropout –≤ —Ä–µ–∂–∏–º–µ –æ–±—É—á–µ–Ω–∏—è!**

**–°–∏–º–ø—Ç–æ–º—ã:**
- Loss ~11-12 –≤–º–µ—Å—Ç–æ –æ–∂–∏–¥–∞–µ–º–æ–≥–æ 2-4
- –ú–æ–¥–µ–ª—å –≤—ã–¥–∞–µ—Ç –±–µ—Å—Å–º—ã—Å–ª–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –∏–ª–∏ –∑–∞—Ü–∏–∫–ª–∏–≤–∞–µ—Ç—Å—è
- –í —Ä–µ–∂–∏–º–µ eval —Ä–∞–±–æ—Ç–∞–µ—Ç –Ω–æ—Ä–º–∞–ª—å–Ω–æ, –ø—Ä–æ–±–ª–µ–º–∞ —Ç–æ–ª—å–∫–æ –≤ train

**–ü—Ä–∏—á–∏–Ω–∞:**
–î–∞–∂–µ "–æ–±—ã—á–Ω—ã–µ" –∑–Ω–∞—á–µ–Ω–∏—è dropout (0.1, 0.05) –º–æ–≥—É—Ç –ø–æ–ª–Ω–æ—Å—Ç—å—é —Ä–∞–∑—Ä—É—à–∏—Ç—å –æ–±—É—á–µ–Ω–∏–µ Whisper –º–æ–¥–µ–ª–µ–π.

**–†–µ—à–µ–Ω–∏–µ:**
–£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å **–≤—Å–µ dropout –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≤ 0.0** –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏:

```yaml
model:
  activation_dropout: 0.0  # Dropout for activation functions
  attention_dropout: 0.0   # Dropout for attention weights
  dropout: 0.0             # General dropout rate
```

**–ü—Ä–æ–≤–µ—Ä–∫–∞:**
- Loss –¥–ª—è baseline –º–æ–¥–µ–ª–∏ (lr=0.0): –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å ~2.5-4.0
- –ï—Å–ª–∏ loss >10 - –Ω–µ–º–µ–¥–ª–µ–Ω–Ω–æ –ø—Ä–æ–≤–µ—Ä—å—Ç–µ dropout!

**–†–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è:**
–ï—Å–ª–∏ –Ω—É–∂–Ω–∞ —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è - –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ `weight_decay` –∏–ª–∏ label smoothing –≤–º–µ—Å—Ç–æ dropout.

### –î—Ä—É–≥–∏–µ —á–∞—Å—Ç—ã–µ –ø—Ä–æ–±–ª–µ–º—ã

#### 1. Out of Memory (CUDA OOM)

**–°–∏–º–ø—Ç–æ–º—ã:**
- `RuntimeError: CUDA out of memory`
- –ü—Ä–æ—Ü–µ—Å—Å —É–±–∏–≤–∞–µ—Ç—Å—è —Å–∏—Å—Ç–µ–º–æ–π

**–†–µ—à–µ–Ω–∏—è:**
```yaml
training:
  train_batch_size: 4              # –£–º–µ–Ω—å—à–∏—Ç—å —Å 8 –¥–æ 4
  gradient_accumulation_steps: 4   # –£–≤–µ–ª–∏—á–∏—Ç—å —Å 2 –¥–æ 4 (—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–π batch = 16)
  fp16: true                       # –í–∫–ª—é—á–∏—Ç—å mixed precision
  eval_batch_size: 8               # –£–º–µ–Ω—å—à–∏—Ç—å evaluation batch
```

**–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ:**
- –ó–∞–∫—Ä—ã—Ç—å –¥—Ä—É–≥–∏–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è, –∏—Å–ø–æ–ª—å–∑—É—é—â–∏–µ GPU
- –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –º–µ–Ω—å—à—É—é –º–æ–¥–µ–ª—å (Whisper Base –≤–º–µ—Å—Ç–æ Small)
- –í–∫–ª—é—á–∏—Ç—å `use_cpu_offload: true` –¥–ª—è –æ—á–µ–Ω—å –±–æ–ª—å—à–∏—Ö –º–æ–¥–µ–ª–µ–π

#### 2. –ú–µ–¥–ª–µ–Ω–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö (DataLoader bottleneck)

**–°–∏–º–ø—Ç–æ–º—ã:**
- GPU utilization < 80%
- –î–æ–ª–≥–æ–µ –æ–∂–∏–¥–∞–Ω–∏–µ –º–µ–∂–¥—É –±–∞—Ç—á–∞–º–∏

**–†–µ—à–µ–Ω–∏—è:**
```yaml
data:
  num_workers: 8                   # –£–≤–µ–ª–∏—á–∏—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–æ—Ä–∫–µ—Ä–æ–≤
  pin_memory: true                 # –í–∫–ª—é—á–∏—Ç—å pinned memory
  processing_and_augmentation_device: "cpu"  # –û–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–∞ CPU
```

**–ü—Ä–æ–≤–µ—Ä–∫–∞:**
- –£–±–µ–¥–∏—Ç–µ—Å—å —á—Ç–æ `clip_durations.tsv` —Å—É—â–µ—Å—Ç–≤—É–µ—Ç (—É—Å–∫–æ—Ä—è–µ—Ç –∑–∞–≥—Ä—É–∑–∫—É –≤ 10+ —Ä–∞–∑)
- –ó–∞–ø—É—Å—Ç–∏—Ç–µ –±–µ–Ω—á–º–∞—Ä–∫: `python tests/dataloader_speed.py`
- Optimal `num_workers` –æ–±—ã—á–Ω–æ —Ä–∞–≤–Ω–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É CPU cores

#### 3. –ú–æ–¥–µ–ª—å –Ω–µ —É–ª—É—á—à–∞–µ—Ç—Å—è / Loss –Ω–µ —É–º–µ–Ω—å—à–∞–µ—Ç—Å—è

**–í–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–∏—á–∏–Ω—ã –∏ —Ä–µ—à–µ–Ω–∏—è:**

1. **–°–ª–∏—à–∫–æ–º –≤—ã—Å–æ–∫–∏–π learning rate:**
   ```yaml
   training:
     learning_rate: 1e-5  # –£–º–µ–Ω—å—à–∏—Ç—å —Å 1e-4
   ```

2. **Encoder –∑–∞–º–æ—Ä–æ–∂–µ–Ω —Å–ª–∏—à–∫–æ–º –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–æ:**
   ```yaml
   model:
     freeze_encoder: true
     unfreeze_last_n_encoder_layers: 2  # –†–∞–∑–º–æ—Ä–æ–∑–∏—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–µ 2 —Å–ª–æ—è
   ```

3. **–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —ç–ø–æ—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è:**
   ```yaml
   training:
     num_train_epochs: 15  # –£–≤–µ–ª–∏—á–∏—Ç—å —Å 10
     use_early_stopping: true
     early_stopping_patience: 5  # –£–≤–µ–ª–∏—á–∏—Ç—å patience
   ```

4. **–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã –≤ TensorBoard:**
   ```bash
   tensorboard --logdir experiments/your_experiment/tensorboard
   # –°–º–æ—Ç—Ä–∏—Ç–µ –Ω–∞ gradient norms - –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —Å—Ç–∞–±–∏–ª—å–Ω—ã–µ, –Ω–µ NaN
   ```

#### 4. –î–∞—Ç–∞—Å–µ—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω

**–°–∏–º–ø—Ç–æ–º—ã:**
- `FileNotFoundError: [Errno 2] No such file or directory: 'data/cv-corpus-22.0-2025-06-20/ru/train.tsv'`

**–†–µ—à–µ–Ω–∏—è:**
1. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π:
   ```bash
   python setup_check.py
   ```

2. –£–±–µ–¥–∏—Ç–µ—Å—å —á—Ç–æ –¥–∞—Ç–∞—Å–µ—Ç —Å–∫–∞—á–∞–Ω –∏ —Ä–∞—Å–ø–∞–∫–æ–≤–∞–Ω:
   ```
   data/
   ‚îî‚îÄ‚îÄ cv-corpus-22.0-2025-06-20/
       ‚îî‚îÄ‚îÄ ru/
           ‚îú‚îÄ‚îÄ train.tsv
           ‚îú‚îÄ‚îÄ dev.tsv
           ‚îú‚îÄ‚îÄ test.tsv
           ‚îî‚îÄ‚îÄ clips/
   ```

3. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—É—Ç—å –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏:
   ```yaml
   data:
     data_dir: "data"
     dataset_path: "cv-corpus-22.0-2025-06-20/ru"
   ```

#### 5. –ú–æ–¥–µ–ª—å –∑–∞—Ü–∏–∫–ª–∏–≤–∞–µ—Ç—Å—è –∏–ª–∏ –≤—ã–¥–∞—ë—Ç –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–π—Å—è —Ç–µ–∫—Å—Ç

**–°–∏–º–ø—Ç–æ–º—ã:**
- Prediction: "—è —è —è —è —è..." –∏–ª–∏ "–ø—Ä–∏–≤–µ—Ç –ø—Ä–∏–≤–µ—Ç –ø—Ä–∏–≤–µ—Ç..."
- –ú–æ–¥–µ–ª—å –ø–æ–≤—Ç–æ—Ä—è–µ—Ç –æ–¥–Ω–∏ –∏ —Ç–µ –∂–µ —Ñ—Ä–∞–∑—ã

**–†–µ—à–µ–Ω–∏—è:**
```yaml
evaluation:
  repetition_penalty: 1.2          # –®—Ç—Ä–∞—Ñ –∑–∞ –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏—è
  no_repeat_ngram_size: 3          # –ë–ª–æ–∫–∏—Ä–æ–≤–∞—Ç—å –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è 3-–≥—Ä–∞–º–º—ã
  num_beams: 1                     # Greedy decoding –æ–±—ã—á–Ω–æ –ª—É—á—à–µ –¥–ª—è ASR
```

**–î–ª—è Whisper –º–æ–¥–µ–ª–µ–π:**
- –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —á—Ç–æ `language` –∏ `task` –ø—Ä–∞–≤–∏–ª—å–Ω–æ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã –≤ –∫–æ–Ω—Ñ–∏–≥–µ
- –£–±–µ–¥–∏—Ç–µ—Å—å —á—Ç–æ processor —Å–æ–∑–¥–∞–Ω —Å language –∏ task –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏

#### 6. WandB –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç / –Ω–µ –ª–æ–≥–∏—Ä—É–µ—Ç –º–µ—Ç—Ä–∏–∫–∏

**–†–µ—à–µ–Ω–∏—è:**
1. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏–Ω:
   ```bash
   wandb login
   ```

2. –í–∫–ª—é—á–∏—Ç–µ –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏:
   ```yaml
   logging:
     use_wandb: true
     wandb_project: "speech-to-text-ru"
   ```

3. –£–±–µ–¥–∏—Ç–µ—Å—å —á—Ç–æ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ñ–ª–∞–≥ `--no-wandb`

4. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ firewall/proxy –Ω–∞—Å—Ç—Ä–æ–π–∫–∏

**–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞:** –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ TensorBoard (–≤—Å–µ–≥–¥–∞ –≤–∫–ª—é—á–µ–Ω –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é):
```bash
tensorboard --logdir experiments
```

#### 7. –¢–µ—Å—Ç—ã –ø–∞–¥–∞—é—Ç —Å –æ—à–∏–±–∫–∞–º–∏ –ø—É—Ç–µ–π

**–ü—Ä–∏—á–∏–Ω–∞:** –¢–µ—Å—Ç—ã –ø—ã—Ç–∞—é—Ç—Å—è —Å–æ–∑–¥–∞—Ç—å –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã –≤–Ω–µ –ø—Ä–æ–µ–∫—Ç–∞

**–†–µ—à–µ–Ω–∏–µ:**
- –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ fixture `temp_dir` –∏–∑ `tests/conftest.py`
- –í—Å–µ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã –¥–æ–ª–∂–Ω—ã —Å–æ–∑–¥–∞–≤–∞—Ç—å—Å—è –≤ `tests/.test_tmp/`
- –ù–ï –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ `tempfile.TemporaryDirectory()` - —Å–º. CLAUDE.md

## üìà –†–µ–∑—É–ª—å—Ç–∞—Ç—ã

–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤ –Ω–∞ Mozilla Common Voice 22.0 Russian dataset (test split):

### Baseline –º–æ–¥–µ–ª–∏ (–±–µ–∑ fine-tuning)

| –ú–æ–¥–µ–ª—å | WER ‚Üì | CER ‚Üì | –ü–∞—Ä–∞–º–µ—Ç—Ä—ã | Inference Speed |
|--------|-------|-------|-----------|-----------------|
| Whisper Tiny | ~35-40% | ~15-20% | 39M | ‚ö°‚ö°‚ö°‚ö°‚ö° |
| Whisper Base | ~25-30% | ~10-15% | 74M | ‚ö°‚ö°‚ö°‚ö° |
| Whisper Small | ~18-22% | ~7-10% | 244M | ‚ö°‚ö°‚ö° |
| Whisper Medium | ~15-18% | ~6-8% | 769M | ‚ö°‚ö° |
| Speech2Text (English) | ~90%+ | ~70%+ | 31M | ‚ö°‚ö°‚ö°‚ö° |

*Speech2Text –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –ø–ª–æ—Ö–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–∞ —Ä—É—Å—Å–∫–æ–º –±–µ–∑ fine-tuning, —Ç.–∫. –æ–±—É—á–µ–Ω–∞ —Ç–æ–ª—å–∫–æ –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º*

### –ü–æ—Å–ª–µ fine-tuning (–ø–ª–∞–Ω–∏—Ä—É–µ–º—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã)

| –ú–æ–¥–µ–ª—å | WER ‚Üì | CER ‚Üì | –ü–∞—Ä–∞–º–µ—Ç—Ä—ã | –≠–ø–æ—Ö –æ–±—É—á–µ–Ω–∏—è | VRAM |
|--------|-------|-------|-----------|---------------|------|
| Whisper Small (frozen encoder) | TBD | TBD | 244M | ~10 | ~5GB |
| Whisper Base (frozen encoder) | TBD | TBD | 74M | ~10 | ~3GB |
| Speech2Text (cross-lingual) | TBD | TBD | 31M | ~15 | ~2GB |
| Custom CNN+Transformer | TBD | TBD | ~50M | ~20 | ~3GB |

**–¶–µ–ª–µ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –ø–æ—Å–ª–µ fine-tuning:**
- **Whisper Small**: WER < 15%, CER < 6%
- **Speech2Text cross-lingual**: WER < 25%, CER < 12%
- **Custom model**: WER < 30%, CER < 15% (baseline –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è)

**–ü—Ä–∏–º–µ—á–∞–Ω–∏—è:**
- –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∑–∞–≤–∏—Å—è—Ç –æ—Ç –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ (LR, batch size, freezing strategy)
- WER/CER –∏–∑–º–µ—Ä—è—é—Ç—Å—è –Ω–∞ test split (~10K –∑–∞–ø–∏—Å–µ–π)
- –í—Å–µ –º–æ–¥–µ–ª–∏ –æ–±—É—á–µ–Ω—ã –Ω–∞ RTX 4070 Ti (12GB VRAM)
- –í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è: Whisper Small ~6-8 —á–∞—Å–æ–≤ –Ω–∞ 10 —ç–ø–æ—Ö

*–¢–∞–±–ª–∏—Ü–∞ –±—É–¥–µ—Ç –æ–±–Ω–æ–≤–ª–µ–Ω–∞ –ø–æ –º–µ—Ä–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤*

### –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–π –æ–±—É—á–µ–Ω–∏—è (Whisper Small)

| –°—Ç—Ä–∞—Ç–µ–≥–∏—è | WER ‚Üì | CER ‚Üì | –í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è | –ü—Ä–∏–º–µ—á–∞–Ω–∏—è |
|-----------|-------|-------|----------------|------------|
| Frozen encoder + decoder training | TBD | TBD | ~6h | –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è |
| Full model fine-tuning | TBD | TBD | ~8h | –ú–æ–∂–µ—Ç –ø–µ—Ä–µ–æ–±—É—á–∏—Ç—å—Å—è |
| Decoder only (frozen encoder) | TBD | TBD | ~5h | –ë—ã—Å—Ç—Ä–æ, –Ω–æ —Ö—É–∂–µ –∫–∞—á–µ—Å—Ç–≤–æ |
| Last 2 encoder layers unfrozen | TBD | TBD | ~7h | –ë–∞–ª–∞–Ω—Å –∫–∞—á–µ—Å—Ç–≤–∞ –∏ –≤—Ä–µ–º–µ–Ω–∏ |

*–≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏*

## üõ† –†–∞–∑—Ä–∞–±–æ—Ç–∫–∞

### –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ

–ü—Ä–æ–µ–∫—Ç –∏—Å–ø–æ–ª—å–∑—É–µ—Ç **pytest** –¥–ª—è comprehensive testing suite.

**–ó–∞–ø—É—Å–∫ –≤—Å–µ—Ö —Ç–µ—Å—Ç–æ–≤:**
```bash
pytest tests/ -v
```

**–ó–∞–ø—É—Å–∫ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Ç–µ—Å—Ç–∞:**
```bash
# –¢–µ—Å—Ç—ã DataManager
pytest tests/test_data_manager.py -v

# –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π —Ç–µ—Å—Ç —Å –≤—ã–≤–æ–¥–æ–º
pytest tests/test_data_manager.py::TestDataManager::test_dataset_info -v -s

# –¢–µ—Å—Ç—ã –º–æ–¥–µ–ª–µ–π
pytest tests/test_models.py -v

# –¢–µ—Å—Ç—ã –º–µ—Ç—Ä–∏–∫
pytest tests/test_metrics.py -v
```

**–ë–µ–Ω—á–º–∞—Ä–∫ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ DataLoader:**
```bash
python tests/dataloader_speed.py
```

**–°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ç–µ—Å—Ç–æ–≤:**
- `tests/conftest.py` - pytest fixtures (`config`, `temp_dir`)
- `tests/test_*.py` - unit —Ç–µ—Å—Ç—ã –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –º–æ–¥—É–ª—è
- `tests/.test_tmp/` - –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã (–∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ—á–∏—Å—Ç–∫–∞)

### –õ–∏–Ω—Ç–∏–Ω–≥ –∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ

–ü—Ä–æ–µ–∫—Ç –∏—Å–ø–æ–ª—å–∑—É–µ—Ç **ruff** –¥–ª—è –ª–∏–Ω—Ç–∏–Ω–≥–∞ –∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (–∑–∞–º–µ–Ω–∞ black + flake8 + isort).

**–ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–¥–∞:**
```bash
# –õ–∏–Ω—Ç–∏–Ω–≥
conda run -n basenn ruff check src/

# –ê–≤—Ç–æ–∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ
conda run -n basenn ruff check --fix src/

# –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
conda run -n basenn ruff format src/
```

**–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–∏–ø–æ–≤ —Å mypy:**
```bash
# –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–∏–ø–æ–≤
conda run -n basenn mypy src/

# –° –∞–≤—Ç–æ—É—Å—Ç–∞–Ω–æ–≤–∫–æ–π type stubs
conda run -n basenn mypy --install-types src/
```

**Pre-commit hook (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ):**
```bash
# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ pre-commit
conda run -n basenn pip install pre-commit

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ hooks
pre-commit install
```

### –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –Ω–æ–≤–æ–π –º–æ–¥–µ–ª–∏

1. **–°–æ–∑–¥–∞–π—Ç–µ –∫–ª–∞—Å—Å –º–æ–¥–µ–ª–∏ –≤ `src/models.py`:**
   ```python
   class NewSTTModel(BaseSTTModel):
       def __init__(self, config):
           super().__init__(config)
           # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏

       def forward(self, input_features, labels=None):
           # Forward pass
           pass

       def generate(self, input_features, **kwargs):
           # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏
           pass
   ```

2. **–î–æ–±–∞–≤—å—Ç–µ –≤ `ModelFactory.create_model()`:**
   ```python
   if config.model.model_type == "new_model":
       return NewSTTModel(config)
   ```

3. **–°–æ–∑–¥–∞–π—Ç–µ YAML –∫–æ–Ω—Ñ–∏–≥ –≤ `configs/`:**
   ```yaml
   model:
     model_name: "author/model-name"
     model_type: "new_model"
     # –°–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
   ```

4. **–î–æ–±–∞–≤—å—Ç–µ —Ç–µ—Å—Ç—ã –≤ `tests/test_models.py`:**
   ```python
   def test_new_model_forward():
       # –¢–µ—Å—Ç forward pass
       pass

   def test_new_model_generate():
       # –¢–µ—Å—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
       pass
   ```

5. **–û–±–Ω–æ–≤–∏—Ç–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é:**
   - –î–æ–±–∞–≤—å—Ç–µ –æ–ø–∏—Å–∞–Ω–∏–µ –≤ README.md (—Ä–∞–∑–¥–µ–ª "–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ –º–æ–¥–µ–ª–∏")
   - –û–±–Ω–æ–≤–∏—Ç–µ CLAUDE.md —Å –¥–µ—Ç–∞–ª—è–º–∏ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã

### –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –Ω–æ–≤–æ–π –º–µ—Ç—Ä–∏–∫–∏

1. **–†–µ–∞–ª–∏–∑—É–π—Ç–µ —Ñ—É–Ω–∫—Ü–∏—é –º–µ—Ç—Ä–∏–∫–∏ –≤ `src/metrics.py`:**
   ```python
   def compute_new_metric(predictions: List[str], references: List[str]) -> float:
       # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏
       return score
   ```

2. **–î–æ–±–∞–≤—å—Ç–µ –≤ `STTMetrics.compute_all_metrics()`:**
   ```python
   new_metric = self.compute_new_metric(predictions, references)
   return MetricResult(
       wer=wer, cer=cer, bleu=bleu,
       new_metric=new_metric  # –î–æ–±–∞–≤–∏—Ç—å –Ω–æ–≤—É—é –º–µ—Ç—Ä–∏–∫—É
   )
   ```

3. **–û–±–Ω–æ–≤–∏—Ç–µ `MetricResult` dataclass:**
   ```python
   @dataclass
   class MetricResult:
       wer: float
       cer: float
       bleu: float
       new_metric: float  # –î–æ–±–∞–≤–∏—Ç—å –ø–æ–ª–µ
   ```

4. **–î–æ–±–∞–≤—å—Ç–µ —Ç–µ—Å—Ç—ã –≤ `tests/test_metrics.py`**

### –ò–∑–º–µ–Ω–µ–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏

1. **–î–æ–±–∞–≤—å—Ç–µ –ø–æ–ª—è –≤ dataclass –≤ `src/config.py`:**
   ```python
   @dataclass
   class ModelConfig:
       model_name: str
       model_type: str
       new_parameter: float = 1.0  # –î–æ–±–∞–≤–∏—Ç—å –Ω–æ–≤—ã–π –ø–∞—Ä–∞–º–µ—Ç—Ä
   ```

2. **–û–±–Ω–æ–≤–∏—Ç–µ default –∫–æ–Ω—Ñ–∏–≥ –≤ `configs/default.yaml`:**
   ```yaml
   model:
     new_parameter: 1.0
   ```

3. **–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –≤ –∫–æ–¥–µ:**
   ```python
   new_value = config.model.new_parameter
   ```

**–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ:** –ù–ï –¥–æ–±–∞–≤–ª—è–π—Ç–µ CLI –∞—Ä–≥—É–º–µ–Ω—Ç—ã –¥–ª—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏. –í—Å–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ —á–µ—Ä–µ–∑ YAML –∫–æ–Ω—Ñ–∏–≥–∏.

## üíº –¢–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π —Å—Ç–µ–∫

### Core ML/DL
- **PyTorch 2.5+** - Deep learning framework
- **torchaudio** - Audio processing
- **HuggingFace Transformers** - Pretrained models (Whisper, Speech2Text)
- **HuggingFace Datasets** - Dataset management

### Configuration & Experiment Management
- **OmegaConf** - Hierarchical configuration
- **Hydra** - Configuration composition
- **TensorBoard** - Training visualization
- **Weights & Biases** - Experiment tracking (optional)

### Data Processing & Augmentation
- **pandas** - Tabular data manipulation
- **numpy** - Numerical computations
- **librosa** - Audio feature extraction
- **Custom augmentation pipeline** (8+ augmentation types)

### Evaluation & Metrics
- **jiwer** - WER/CER/MER/WIL metrics
- **evaluate (HuggingFace)** - BLEU and other NLP metrics
- **Custom performance analyzer** - Error breakdown, duration/length analysis

### Development Tools
- **pytest** - Testing framework
- **mypy** - Static type checking
- **ruff** - Fast linting & formatting (replaces black/flake8/isort)
- **rich** - Beautiful terminal output
- **Jupyter** - Interactive development

### Production Ready
- **Separate scripts** for train/eval/inference
- **Comprehensive testing** (9+ test modules)
- **Type hints** throughout codebase
- **Detailed logging** with structured output
- **Reproducible experiments** (fixed seeds, config versioning)

## ü§ù –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–ª—è –ø–æ—Ä—Ç—Ñ–æ–ª–∏–æ

–≠—Ç–æ—Ç –ø—Ä–æ–µ–∫—Ç –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –ø–æ–¥—Ö–æ–¥ –∫ ML/DL —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ:

### 1. Clean Code & Architecture
- ‚úÖ **–ú–æ–¥—É–ª—å–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞** —Å —á–µ—Ç–∫–∏–º —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ–º –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏
- ‚úÖ **Type hints** –≤–æ –≤—Å–µ–º –∫–æ–¥–µ (mypy compatible)
- ‚úÖ **Comprehensive documentation** (README, CLAUDE.md, docstrings)
- ‚úÖ **SOLID –ø—Ä–∏–Ω—Ü–∏–ø—ã** (Factory pattern, dataclasses, protocols)
- ‚úÖ **–ü–æ–Ω—è—Ç–Ω—ã–µ naming conventions** –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞

### 2. MLOps –ü—Ä–∞–∫—Ç–∏–∫–∏
- ‚úÖ **–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω–æ–µ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ** (OmegaConf, YAML-based)
- ‚úÖ **Experiment tracking** (TensorBoard + WandB)
- ‚úÖ **Reproducibility** (fixed seeds, config versioning, requirements.txt)
- ‚úÖ **Model versioning** (checkpoint management, best model selection)
- ‚úÖ **Logging & monitoring** (structured logging, metrics tracking)
- ‚úÖ **Production inference** (batch processing, RTF calculation)

### 3. Deep Learning Expertise
- ‚úÖ **Transfer learning** (fine-tuning pretrained Whisper/Speech2Text)
- ‚úÖ **Cross-lingual transfer** (English‚ÜíRussian adaptation)
- ‚úÖ **Custom architectures** (CNN + Transformer + CTC)
- ‚úÖ **Advanced training techniques** (early stopping, LR scheduling, gradient accumulation)
- ‚úÖ **Model optimization** (FP16 mixed precision, memory management)
- ‚úÖ **Flexible freezing strategies** (fine-grained layer control)

### 4. Data Engineering
- ‚úÖ **Efficient data loading** (PyTorch DataLoader, caching, multiprocessing)
- ‚úÖ **Data augmentation pipeline** (8+ types: noise, speed, pitch, SpecAugment, reverb)
- ‚úÖ **Audio preprocessing** (resampling, normalization, silence trimming)
- ‚úÖ **Custom collation** (dynamic padding, CPU/GPU modes)
- ‚úÖ **Dataset analysis** (EDA notebooks, statistics)

### 5. Evaluation & Metrics
- ‚úÖ **Comprehensive metrics** (WER, CER, BLEU, MER, WIL)
- ‚úÖ **Error analysis** (substitutions, deletions, insertions breakdown)
- ‚úÖ **Performance segmentation** (by duration, text length)
- ‚úÖ **Anti-repetition techniques** (repetition penalty, n-gram blocking)
- ‚úÖ **Baseline comparisons** (pretrained vs fine-tuned)

### 6. Software Engineering
- ‚úÖ **Comprehensive testing** (pytest, 9+ test modules, fixtures)
- ‚úÖ **Code quality tools** (ruff linting, mypy type checking)
- ‚úÖ **Git best practices** (.gitignore, structured commits)
- ‚úÖ **CI/CD ready** (automated testing, reproducible environments)
- ‚úÖ **Documentation** (README, inline comments, type hints)

### 7. Research & Experimentation
- ‚úÖ **Model comparison framework** (run_experiments.py)
- ‚úÖ **Hyperparameter search support** (multiple LR schedulers)
- ‚úÖ **Ablation studies** (freezing strategies, augmentation impact)
- ‚úÖ **Jupyter notebooks** (EDA, baseline preparation, debugging)
- ‚úÖ **–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏ –≤—ã–≤–æ–¥—ã** (metrics tables, training curves)

**–≠—Ç–æ—Ç –ø—Ä–æ–µ–∫—Ç –≥–æ—Ç–æ–≤ –∫ –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–∏ –∫–∞–∫ –ø—Ä–∏–º–µ—Ä production-ready ML engineering.**

## üìù –õ–∏—Ü–µ–Ω–∑–∏—è

MIT License - —Å–º. [LICENSE](LICENSE) —Ñ–∞–π–ª –¥–ª—è –¥–µ—Ç–∞–ª–µ–π.

## üôè –ë–ª–∞–≥–æ–¥–∞—Ä–Ω–æ—Å—Ç–∏

- **Mozilla Foundation** - –∑–∞ –æ—Ç–∫—Ä—ã—Ç—ã–π –¥–∞—Ç–∞—Å–µ—Ç Common Voice 22.0
- **OpenAI** - –∑–∞ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –∏ pretrained –º–æ–¥–µ–ª–∏ Whisper
- **Meta AI (Facebook)** - –∑–∞ –º–æ–¥–µ–ª–∏ Speech2Text –∏ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è –≤ –æ–±–ª–∞—Å—Ç–∏ ASR
- **HuggingFace** - –∑–∞ –±–∏–±–ª–∏–æ—Ç–µ–∫—É Transformers –∏ —ç–∫–æ—Å–∏—Å—Ç–µ–º—É ML –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤
- **PyTorch Team** - –∑–∞ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ PyTorch –∏ torchaudio
- **Open Source Community** - –∑–∞ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ jiwer, ruff, pytest –∏ –¥—Ä—É–≥–∏–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã

## üìö –ü–æ–ª–µ–∑–Ω—ã–µ —Å—Å—ã–ª–∫–∏

- **–î–∞—Ç–∞—Å–µ—Ç**: [Mozilla Common Voice](https://commonvoice.mozilla.org/en/datasets)
- **Whisper Paper**: [Robust Speech Recognition via Large-Scale Weak Supervision](https://arxiv.org/abs/2212.04356)
- **Speech2Text**: [HuggingFace Model Card](https://huggingface.co/facebook/s2t-small-librispeech-asr)
- **HuggingFace Transformers**: [Documentation](https://huggingface.co/docs/transformers)
- **PyTorch**: [Official Website](https://pytorch.org/)

## üìß –ö–æ–Ω—Ç–∞–∫—Ç—ã

–î–ª—è –≤–æ–ø—Ä–æ—Å–æ–≤, –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –∏–ª–∏ —Å–æ—Ç—Ä—É–¥–Ω–∏—á–µ—Å—Ç–≤–∞:

- **GitHub Issues**: –°–æ–∑–¥–∞–π—Ç–µ issue –≤ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏
- **Email**: your.email@example.com (–∑–∞–º–µ–Ω–∏—Ç–µ –Ω–∞ —Å–≤–æ–π)
- **LinkedIn**: [Your Profile](https://linkedin.com/in/yourprofile) (–∑–∞–º–µ–Ω–∏—Ç–µ –Ω–∞ —Å–≤–æ–π)

---

<div align="center">

**–≠—Ç–æ—Ç –ø—Ä–æ–µ–∫—Ç –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –ø–æ–¥—Ö–æ–¥ –∫ ML/DL —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ**
*Production-ready –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ ‚Ä¢ MLOps –ø—Ä–∞–∫—Ç–∏–∫–∏ ‚Ä¢ Comprehensive testing*

‚≠ê –ï—Å–ª–∏ –ø—Ä–æ–µ–∫—Ç –±—ã–ª –ø–æ–ª–µ–∑–µ–Ω, –ø–æ—Å—Ç–∞–≤—å—Ç–µ –∑–≤–µ–∑–¥—É –Ω–∞ GitHub!

</div>
